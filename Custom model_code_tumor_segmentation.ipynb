{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12173636,"sourceType":"datasetVersion","datasetId":7667134},{"sourceId":12599436,"sourceType":"datasetVersion","datasetId":7958024}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\n\n# Check if GPU is detected\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nprint(tf.test.gpu_device_name())  # Should output something like '/device:GPU:0'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T08:58:36.303186Z","iopub.execute_input":"2025-07-29T08:58:36.303854Z","execution_failed":"2025-07-29T08:58:36.739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Enable mixed precision properly\n# policy = tf.keras.mixed_precision.Policy('mixed_float16')\n# tf.keras.mixed_precision.set_global_policy(policy)\nimport tensorflow as tf\ntf.keras.mixed_precision.set_global_policy('float32')\n# Make sure your model's final layer outputs float32 for stability\n# Add this to your model's last layer:\n# outputs = tf.cast(outputs, tf.float32)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        # Enable memory growth (allocates memory as needed)\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(e)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom pathlib import Path\nimport os\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom glob import glob\n\n# For neural network\nimport tensorflow as tf\n\n# For Accuracy metric\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\nimport time\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import layers","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_dir = '/kaggle/input/hyper-curated-busi/hyper_curated_busi'\nnormal_dir = os.path.join(base_dir, 'normal')\nbenign_dir = os.path.join(base_dir, 'benign')\nmalignant_dir = os.path.join(base_dir, 'malignant')\nprint(normal_dir)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_images_and_masks(directory, class_label, has_mask=True):\n    images = []\n    masks = []\n    labels = []\n    # Get all image files (excluding masks)\n    image_files = [f for f in os.listdir(directory) if '_mask' not in f and f.endswith('.png')]\n\n    for img_name in image_files:\n        # Load image\n        img_path = os.path.join(directory, img_name)\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n        if img is None:\n            continue\n\n        # Resize image (e.g., to 256x256)\n        img = cv2.resize(img, (256, 256))\n        images.append(img)\n        labels.append(class_label)\n\n        # Load mask if applicable\n        if has_mask:\n            mask_name = img_name.replace('.png', '_mask.png')\n            mask_path = os.path.join(directory, mask_name)\n            if os.path.exists(mask_path):\n                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n                mask = cv2.resize(mask, (256, 256))\n                # Binarize mask (0 or 255)\n                mask = (mask > 0).astype(np.uint8) * 255\n                masks.append(mask)\n            else:\n                masks.append(np.zeros((256, 256), dtype=np.uint8))  # Empty mask if not found\n        else:\n            masks.append(np.zeros((256, 256), dtype=np.uint8))  # No mask for normal images\n\n    return images, masks, labels\n\n# Load data for each class\nnormal_images, normal_masks, normal_labels = load_images_and_masks(normal_dir, 'normal', has_mask=False)\nbenign_images, benign_masks, benign_labels = load_images_and_masks(benign_dir, 'benign', has_mask=True)\nmalignant_images, malignant_masks, malignant_labels = load_images_and_masks(malignant_dir, 'malignant', has_mask=True)\n\n# Combine all data\nall_images = normal_images + benign_images + malignant_images\nall_masks = normal_masks + benign_masks + malignant_masks\nall_labels = normal_labels + benign_labels + malignant_labels\n\n# Convert to numpy arrays\nall_images = np.array(all_images)\nall_masks = np.array(all_masks)\nall_labels = np.array(all_labels)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Normalize images and masks\nall_images = all_images / 255.0  # Normalize to [0, 1]\nall_masks = all_masks / 255.0    # Normalize to [0, 1]","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split data (80% train, 20% test)\nX_train, X_test, y_train, y_test, labels_train, labels_test = train_test_split(\n    all_images, all_masks, all_labels,\n    test_size=0.2, random_state=40, stratify=all_labels\n)\n\nX_val, X_test1, y_val, y_test1, labels_val, labels_test1 = train_test_split(\n    X_test, y_test, labels_test,\n    test_size=0.95, random_state=40, stratify=labels_test\n)\n\n\n# Reshape for deep learning models (add channel dimension)\nX_train = X_train[..., np.newaxis]  # Shape: (n_train, 256, 256, 1)\nX_test = X_test[..., np.newaxis]    # Shape: (n_test, 256, 256, 1)\nX_val = X_val[..., np.newaxis]    # Shape: (n_test, 256, 256, 1)\ny_train = y_train[..., np.newaxis]  # Shape: (n_train, 256, 256, 1)\ny_test = y_test[..., np.newaxis]    # Shape: (n_test, 256, 256, 1)\ny_val = y_val[..., np.newaxis]    # Shape: (n_test, 256, 256, 1)\n\nprint(f\"Training set: {X_train.shape}, {y_train.shape},{labels_train.shape}\")\nprint(f\"Testing set: {X_test.shape}, {y_test.shape},{labels_test.shape}\")\nprint(f\"Validation set: {X_val.shape}, {y_val.shape},{labels_val.shape}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import Counter\n\nprint(\"Train label distribution:\", Counter(labels_train))\nprint(\"Test label distribution:\", Counter(labels_test))\nprint(\"Valdiation label distribution:\", Counter(labels_val))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_labels_train = pd.get_dummies(labels_train).astype(int)\ndf_labels_test = pd.get_dummies(labels_test).astype(int)\ndf_labels_val = pd.get_dummies(labels_val).astype(int)\n\n# Optional: reorder columns to follow a consistent order\n#df_labels = df_labels[['malignant', 'benign', 'normal']]  # reorder as needed\n\nprint(sum(df_labels_train['normal']))\ndf_labels_val.head()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import albumentations as A\n\n# Define augmentation pipeline\naugmentation = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.Rotate(limit=30, p=0.5),\n    A.RandomBrightnessContrast(p=0.3),\n    A.RandomCrop(height=224, width=224, p=0.3),\n    A.Resize(256, 256)  # Ensure output size\n])\n\n# Apply augmentation to training data\naugmented_images = []\naugmented_masks = []\naugmented_labels = []\ndf_labels_train_np=np.array(df_labels_train)\nfor img, mask,label in zip(X_train, y_train,df_labels_train_np):\n    aug = augmentation(image=img.squeeze(), mask=mask.squeeze())\n    augmented_images.append(aug['image'][..., np.newaxis])\n    augmented_masks.append(aug['mask'][..., np.newaxis])\n    augmented_labels.append(label)\n    \n# Convert to numpy arrays\naugmented_images = np.array(augmented_images)\naugmented_masks = np.array(augmented_masks)\naugmented_labels=np.array(augmented_labels)\nprint(df_labels_train.shape)\nprint(augmented_labels.shape)\n# Combine original and augmented data\nX_train_aug = np.concatenate([X_train, augmented_images], axis=0)\ny_train_aug = np.concatenate([y_train, augmented_masks], axis=0)\ndf_labels_train_aug=np.concatenate([df_labels_train, augmented_labels], axis=0)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Training set: {X_train_aug.shape}, {y_train_aug.shape},{df_labels_train_aug.shape}\")\nprint(f\"Testing set: {X_test.shape}, {y_test.shape},{labels_test.shape}\")\nprint(f\"Validation set: {X_val.shape}, {y_val.shape},{labels_val.shape}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, Model, regularizers\nfrom tensorflow.keras.applications import EfficientNetB4\nimport tensorflow.keras.backend as K\n\n\nclass SpatialAttention(layers.Layer):\n    \"\"\"Spatial Attention Module for feature refinement\"\"\"\n    def __init__(self, **kwargs):\n        super(SpatialAttention, self).__init__(**kwargs)\n        \n    def build(self, input_shape):\n        self.conv = layers.Conv2D(1, 7, padding='same', activation='sigmoid')\n        super(SpatialAttention, self).build(input_shape)\n        \n    def call(self, inputs):\n        avg_pool = tf.reduce_mean(inputs, axis=-1, keepdims=True)\n        max_pool = tf.reduce_max(inputs, axis=-1, keepdims=True)\n        concat = layers.Concatenate()([avg_pool, max_pool])\n        attention = self.conv(concat)\n        return inputs * attention\n\nclass ChannelAttention(layers.Layer):\n    \"\"\"Channel Attention Module (SE block variant)\"\"\"\n    def __init__(self, ratio=16, **kwargs):\n        super(ChannelAttention, self).__init__(**kwargs)\n        self.ratio = ratio\n        \n    def build(self, input_shape):\n        self.channels = input_shape[-1]\n        self.gap = layers.GlobalAveragePooling2D()\n        self.fc1 = layers.Dense(self.channels // self.ratio, activation='relu')\n        self.fc2 = layers.Dense(self.channels, activation='sigmoid')\n        self.reshape = layers.Reshape((1, 1, self.channels))\n        super(ChannelAttention, self).build(input_shape)\n        \n    def call(self, inputs):\n        x = self.gap(inputs)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        x = self.reshape(x)\n        return inputs * x\n\nclass CBAM(layers.Layer):\n    \"\"\"Convolutional Block Attention Module\"\"\"\n    def __init__(self, **kwargs):\n        super(CBAM, self).__init__(**kwargs)\n        self.channel_attention = ChannelAttention()\n        self.spatial_attention = SpatialAttention()\n        \n    def call(self, inputs):\n        x = self.channel_attention(inputs)\n        x = self.spatial_attention(x)\n        return x\n\nclass ResidualBlock(layers.Layer):\n    \"\"\"Enhanced Residual Block with attention\"\"\"\n    def __init__(self, filters, strides=1, use_attention=True, dropout_rate=0.1, **kwargs):\n        super(ResidualBlock, self).__init__(**kwargs)\n        self.filters = filters\n        self.strides = strides\n        self.use_attention = use_attention\n        self.dropout_rate = dropout_rate\n        \n    def build(self, input_shape):\n        # Main path\n        self.conv1 = layers.Conv2D(self.filters, 3, strides=self.strides, padding='same',\n                                  kernel_regularizer=regularizers.l2(1e-4))\n        self.bn1 = layers.BatchNormalization()\n        self.conv2 = layers.Conv2D(self.filters, 3, padding='same',\n                                  kernel_regularizer=regularizers.l2(1e-4))\n        self.bn2 = layers.BatchNormalization()\n        self.dropout = layers.Dropout(self.dropout_rate)\n        \n        # Shortcut path\n        if self.strides != 1 or input_shape[-1] != self.filters:\n            self.shortcut_conv = layers.Conv2D(self.filters, 1, strides=self.strides, padding='same')\n            self.shortcut_bn = layers.BatchNormalization()\n        else:\n            self.shortcut_conv = None\n            \n        # Attention\n        if self.use_attention:\n            self.attention = CBAM()\n            \n        super(ResidualBlock, self).build(input_shape)\n        \n    def call(self, inputs, training=None):\n        # Main path\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = layers.Activation('swish')(x)  # Swish activation performs better\n        x = self.dropout(x, training=training)\n        \n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        \n        # Shortcut path\n        if self.shortcut_conv:\n            shortcut = self.shortcut_conv(inputs)\n            shortcut = self.shortcut_bn(shortcut, training=training)\n        else:\n            shortcut = inputs\n            \n        # Add and activate\n        x = layers.Add()([x, shortcut])\n        \n        # Apply attention\n        if self.use_attention:\n            x = self.attention(x)\n            \n        x = layers.Activation('swish')(x)\n        return x\n\nclass PyramidPooling(layers.Layer):\n    \"\"\"Pyramid Pooling Module for multi-scale context\"\"\"\n    def __init__(self, filters, **kwargs):\n        super(PyramidPooling, self).__init__(**kwargs)\n        self.filters = filters\n        \n    def build(self, input_shape):\n        self.pool_sizes = [1, 2, 3, 6]\n        self.convs = []\n        for _ in self.pool_sizes:\n            self.convs.append([\n                layers.Conv2D(self.filters // len(self.pool_sizes), 1, padding='same'),\n                layers.BatchNormalization(),\n                layers.Activation('swish')\n            ])\n        super(PyramidPooling, self).build(input_shape)\n        \n    def call(self, inputs, training=None):\n        h, w = tf.shape(inputs)[1], tf.shape(inputs)[2]\n        pools = []\n        \n        for i, pool_size in enumerate(self.pool_sizes):\n            pool = layers.AveragePooling2D(pool_size, strides=pool_size)(inputs)\n            for layer in self.convs[i]:\n                if isinstance(layer, layers.BatchNormalization):\n                    pool = layer(pool, training=training)\n                else:\n                    pool = layer(pool)\n            pool = tf.image.resize(pool, [h, w])\n            pools.append(pool)\n            \n        return layers.Concatenate()(pools)\n\n# Dice and Focal Loss Functions\ndef dice_coefficient(y_true, y_pred, smooth=1e-6):\n    \"\"\"Dice coefficient for segmentation evaluation\"\"\"\n    y_true_f = K.flatten(K.cast(y_true, dtype='float32'))\n    y_pred_f = K.flatten(K.cast(y_pred, dtype='float32'))\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_coefficient(y_true, y_pred)\n\ndef focal_loss(y_true, y_pred, alpha=0.8, gamma=2.0):\n    epsilon = K.epsilon()\n    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n    p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n    alpha_factor = K.ones_like(y_true) * alpha\n    alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n    cross_entropy = -K.log(p_t)\n    weight = alpha_t * K.pow((1 - p_t), gamma)\n    loss = weight * cross_entropy\n    return K.mean(K.sum(loss, axis=1))\n\ndef combined_loss(y_true_seg, y_pred_seg, y_true_cls, y_pred_cls, seg_weight=0.7):\n    seg_loss = dice_loss(y_true_seg, y_pred_seg) + K.binary_crossentropy(y_true_seg, y_pred_seg)\n    cls_loss = focal_loss(y_true_cls, y_pred_cls)\n    return seg_weight * seg_loss + (1 - seg_weight) * cls_loss\n\n# Main model definition\ndef model_seg_class_optimized(inp_size=(256, 256, 3), num_classes=3, base_filters=32):\n    inputs = layers.Input(inp_size, name='input')\n    \n    # Data augmentation and normalization inside the model (NOT passed as input_tensor)\n    aug = layers.RandomFlip(\"horizontal\")(inputs)\n    aug = layers.RandomRotation(0.1)(aug)\n    aug = layers.RandomZoom(0.1)(aug)\n    aug = layers.Rescaling(1./255)(aug)  # Changed Normalization to Rescaling for simplicity\n\n    # EfficientNet backbone with raw input (augmented tensor is used downstream)\n    backbone = EfficientNetB7(input_tensor=inputs, weights='imagenet', include_top=False)\n    x = backbone(aug)  # Pass augmented input through the backbone\n    \n    # Feature extraction\n    feature_layers = ['block2a_expand_activation', 'block3a_expand_activation',\n                      'block4a_expand_activation', 'block6a_expand_activation']\n    skip_connections = [backbone.get_layer(name).output for name in feature_layers]\n    \n    bottom_features = backbone.output\n    ppm = PyramidPooling(base_filters * 16)(bottom_features)\n    bottom_features = layers.Concatenate()([bottom_features, ppm])\n    \n    x = ResidualBlock(base_filters * 16, use_attention=True)(bottom_features)\n    x = ResidualBlock(base_filters * 16, use_attention=True)(x)\n    \n    cls_features = [layers.GlobalAveragePooling2D()(x)]\n\n    decoder_filters = [base_filters * 8, base_filters * 4, base_filters * 2, base_filters]\n\n    for i, (skip, filters) in enumerate(zip(reversed(skip_connections), decoder_filters)):\n        x = layers.UpSampling2D(2, interpolation='bilinear')(x)\n        skip_processed = layers.Conv2D(filters, 1, padding='same')(skip)\n        skip_processed = layers.BatchNormalization()(skip_processed)\n        skip_processed = layers.Activation('swish')(skip_processed)\n        skip_processed = CBAM()(skip_processed)\n        \n        x = layers.Concatenate()([skip_processed, x])\n        x = ResidualBlock(filters, use_attention=True, dropout_rate=0.1)(x)\n        x = ResidualBlock(filters, use_attention=True, dropout_rate=0.1)(x)\n\n        if i < 3:\n            cls_features.append(layers.GlobalAveragePooling2D()(x))\n\n    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n\n    seg_out = layers.Conv2D(1, 3, padding='same')(x)\n    seg_out = layers.BatchNormalization()(seg_out)\n    seg_out = layers.Activation('sigmoid', name='seg_out')(seg_out)\n\n    cls_combined = layers.Concatenate()(cls_features)\n    cls_x = layers.Dense(512, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(cls_combined)\n    cls_x = layers.Dropout(0.3)(cls_x)\n    cls_x = layers.Dense(256, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(cls_x)\n    cls_x = layers.Dropout(0.2)(cls_x)\n    cls_x = layers.Dense(128, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(cls_x)\n    cls_out = layers.Dense(num_classes, activation='softmax', name='cls_out')(cls_x)\n\n    model = Model(inputs=inputs, outputs=[seg_out, cls_out], name='OptimizedBUSIModel')\n    return model\n\nclass DiceBCELoss(tf.keras.losses.Loss):\n    def call(self, y_true, y_pred):\n        return dice_loss(y_true, y_pred) + K.binary_crossentropy(y_true, y_pred)\n\n\ndef compile_model(model, learning_rate=1e-4):\n    steps_per_epoch = 100\n    total_steps = steps_per_epoch * 200\n    lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n        initial_learning_rate=learning_rate,\n        decay_steps=total_steps,\n        alpha=0.1\n    )\n    optimizer = tf.keras.optimizers.AdamW(\n        learning_rate=lr_schedule,\n        weight_decay=1e-4,\n        beta_1=0.9,\n        beta_2=0.999,\n        epsilon=1e-7\n    )\n\n    model.compile(\n        optimizer=optimizer,\n        loss={\n            'seg_out': DiceBCELoss(),\n            'cls_out': focal_loss\n        },\n        loss_weights={'seg_out': 0.7, 'cls_out': 0.3},\n        metrics={\n            'seg_out': [dice_coefficient, 'binary_accuracy'],\n            'cls_out': ['accuracy', 'categorical_accuracy']\n        }\n    )\n    return model\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model=model_seg_class()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # Create optimized model\nmodel = model_seg_class_optimized(inp_size=(256, 256, 3), num_classes=3)\n    \n    # Compile with optimal settings\nmodel = compile_model(model)\n    \n    # Print model summary\n# print(model.summary())\n    \n    # Additional callbacks for training\ncallbacks = [\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss', factor=0.5, patience=10, min_lr=1e-7\n        ),\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss', patience=20, restore_best_weights=True\n        ),\n        tf.keras.callbacks.ModelCheckpoint(\n            'best_busi_model.h5', monitor='val_loss', save_best_only=True\n        )\n    ]\n    \n    # print(\"Model ready for training on BUSI dataset!\")\n    # print(\"Key optimizations applied:\")\n    # print(\"- EfficientNetB4 backbone with ImageNet pretraining\")\n    # print(\"- CBAM attention mechanisms\")\n    # print(\"- Residual connections with proper regularization\") \n    # print(\"- Pyramid pooling for multi-scale context\")\n    # print(\"- FPN-style decoder\")\n    # print(\"- Advanced loss functions (Dice+BCE, Focal)\")\n    # print(\"- Built-in data augmentation\")\n    # print(\"- AdamW optimizer with cosine decay\")\n    # print(\"- Multi-scale classification features\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model.summary()\n# print(\"\\n\\n## Model Plot\")\n# plot_model(model, show_shapes=True)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def dice_bce_loss(y_true, y_pred, axis=(1, 2, 3), smooth=1e-4):\n#     y_true = tf.cast(y_true, tf.float32)\n#     y_pred_sigmoid = tf.keras.activations.sigmoid(y_pred)  # Optional: if logits\n\n#     # Binary cross-entropy\n#     bce = tf.keras.losses.binary_crossentropy(y_true, y_pred_sigmoid)\n\n#     # Dice loss\n#     y_pred_bin = tf.cast(y_pred_sigmoid > 0.5, tf.float32)\n#     tp = tf.reduce_sum(y_true * y_pred_bin, axis=axis)\n#     fn = tf.reduce_sum(y_true * (1 - y_pred_bin), axis=axis)\n#     fp = tf.reduce_sum((1 - y_true) * y_pred_bin, axis=axis)\n#     dice_score = (2 * tp + smooth) / (2 * tp + fn + fp + smooth)\n#     dice_loss = 1.0 - tf.reduce_mean(dice_score)\n\n#     # Combine\n#     return dice_loss + tf.reduce_mean(bce)\n\ndef dice(y_true, y_pred, axis=(0, 1, 2), smooth=0.0001, thr=0.5):\n    y_true = tf.cast(y_true, tf.float32) # (B, H, W, C)\n    y_pred = tf.cast(y_pred > thr, tf.float32) # (B, H, W, C)\n    tp = tf.math.reduce_sum(y_true * y_pred, axis=axis) # calculate True Positive\n    fn = tf.math.reduce_sum(y_true * (1 - y_pred), axis=axis) # calculate False Negative\n    fp = tf.math.reduce_sum((1 - y_true) * y_pred, axis=axis) # calculate False Positive\n    dice = (2*tp + smooth) / (2*tp + fn + fp + smooth) # calculate Dice score\n    dice = tf.math.reduce_mean(dice) # average over all classes\n    return dice # Dice loss is 1 - Dice score\n\ndef iou(y_true, y_pred, axis=(0, 1, 2), smooth=0.0001, thr=0.5):\n    y_true = tf.cast(y_true, tf.float32) # (B, H, W, C)\n    y_pred = tf.cast(y_pred > thr, tf.float32) # (B, H, W, C)\n    tp = tf.math.reduce_sum(y_true * y_pred, axis=axis) # calculate True Positive\n    fn = tf.math.reduce_sum(y_true * (1 - y_pred), axis=axis) # calculate False Negative\n    fp = tf.math.reduce_sum((1 - y_true) * y_pred, axis=axis) # calculate False Positive\n    iou = (tp + smooth) / (tp + fn + fp + smooth) # calculate Dice score\n    iou = tf.math.reduce_mean(iou) # average over all classes\n    return iou # Dice loss is 1 - Dice score","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model.compile(\n#     optimizer='adam',\n#     loss={\n#         'seg_out': 'BinaryCrossentropy',\n#         'cls_out': 'CategoricalCrossentropy'\n#     },\n#     metrics={\n#         'seg_out': [dice, iou], # You might use Dice Coefficient or IoU here\n#         'cls_out': ['accuracy']\n#     }\n# )","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(model.output_names)\nprint(X_train_aug.shape)  # (N, 256, 256, 3)\nprint(y_train_aug.shape)          # e.g. (1000, 256, 256, 1)\nprint(df_labels_train_aug.shape)  # e.g. (1000, 3)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# sample_X = X_train_aug[:2]\n# sample_y = {\n#     'seg_out': y_train_aug[:2],\n#     'cls_out': df_labels_train_aug[:2]\n# }\n# # print(model.predict(sample_X))\n# # print(model.train_on_batch(sample_X, sample_y))\n# results = model.train_on_batch(sample_X, sample_y)\n# print(\"Train on batch results:\", results)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\n# Check if GPU is detected\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nprint(tf.test.gpu_device_name())  # Should output something like '/device:GPU:0'","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ['TF_GPU_TIMER_LOG_LEVEL'] = '3'","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nstart=time.time()\n\nhistory = model.fit(\n    x=X_train_aug,\n    y={'seg_out': y_train_aug, 'cls_out': df_labels_train_aug},\n    batch_size=8,\n    epochs=5,\n    validation_data=(X_val, {'seg_out': y_val, 'cls_out': df_labels_val}),\n)\n\nend=time.time()\nprint(f\"\\n\\nTraining time: {(end-start):.2f} seconds\")\nmodel.save('/kaggle/working/pc.h5')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seg_preds, cls_preds = model.predict(X_test)\n ","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"true_labels = df_labels_test.values.argmax(axis=1)\n\n# Predicted class indices\npredicted_labels = cls_preds.argmax(axis=1)\n\n# Accuracy\nacc = accuracy_score(true_labels, predicted_labels)\nprint(f\"\\n## Accuracy: {acc:.4f}\")\n\n# Classification report\nreport = classification_report(true_labels, predicted_labels, target_names=['benign', 'malignant', 'normal'])\nprint(\"\\n## Classification Report:\\n\", report)\n\n#segmentation\nprint(\"\\n## Dice Score:\\n\",dice(y_test,seg_preds).numpy())\nprint(\"\\n## IOU:\\n\",iou(y_test,seg_preds).numpy(),\"\\n\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_prediction(image, predicted_mask, ground_truth_mask=None):\n    plt.figure(figsize=(12, 4))\n    predicted_mask =  (predicted_mask > 0.5).astype(np.float32)\n    # Fix image shape\n    image_2d = np.squeeze(image)\n    if image_2d.ndim == 3:  # if shape is (H, W, C)\n        image_2d = image_2d[:, :, 0]  # Take first channel\n\n    # Plot input image\n    plt.subplot(1, 3 if ground_truth_mask is not None else 2, 1)\n    plt.imshow(image_2d, cmap='gray')\n    plt.title(\"Ultrasound Image\")\n    plt.axis('off')\n\n    # Ground truth\n    if ground_truth_mask is not None:\n        gt_mask = np.squeeze(ground_truth_mask)\n        plt.subplot(1, 3, 2)\n        plt.imshow(gt_mask, cmap='gray')\n        plt.title(\"Ground Truth Mask\")\n        plt.axis('off')\n\n    # Predicted mask\n    pred_mask = np.squeeze(predicted_mask)\n    plt.subplot(1, 3 if ground_truth_mask is not None else 2, 3 if ground_truth_mask is not None else 2)\n    plt.imshow(pred_mask, cmap='gray')\n    plt.title(\"Predicted Mask\")\n    plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n=18\nplot_prediction(X_test[n],seg_preds[n],y_test[n])","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(10,20):\n    plot_prediction(X_test[i],seg_preds[i],y_test[i])","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-29T08:58:36.741Z"}},"outputs":[],"execution_count":null}]}