{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12173636,"sourceType":"datasetVersion","datasetId":7667134},{"sourceId":12599436,"sourceType":"datasetVersion","datasetId":7958024},{"sourceId":495086,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":393095,"modelId":411707},{"sourceId":495256,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":393095,"modelId":411707},{"sourceId":497828,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":393095,"modelId":411707}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom pathlib import Path\nimport os\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd\nfrom glob import glob\n\n# For neural network\nimport tensorflow as tf\n\n# For Accuracy metric\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\nimport time\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import load_model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:33:49.253850Z","iopub.execute_input":"2025-07-30T04:33:49.254499Z","iopub.status.idle":"2025-07-30T04:34:02.823987Z","shell.execute_reply.started":"2025-07-30T04:33:49.254458Z","shell.execute_reply":"2025-07-30T04:34:02.823190Z"}},"outputs":[{"name":"stderr","text":"2025-07-30 04:33:50.952574: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753850031.133752      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753850031.185874      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"base_dir = '/kaggle/input/hyper-curated-busi/hyper_curated_busi'\nnormal_dir = os.path.join(base_dir, 'normal')\nbenign_dir = os.path.join(base_dir, 'benign')\nmalignant_dir = os.path.join(base_dir, 'malignant')\nprint(normal_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:34:02.825036Z","iopub.execute_input":"2025-07-30T04:34:02.825410Z","iopub.status.idle":"2025-07-30T04:34:02.830337Z","shell.execute_reply.started":"2025-07-30T04:34:02.825392Z","shell.execute_reply":"2025-07-30T04:34:02.829495Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/hyper-curated-busi/hyper_curated_busi/normal\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def load_images_and_masks(directory, class_label, has_mask=True):\n    images = []\n    masks = []\n    labels = []\n    # Get all image files (excluding masks)\n    image_files = [f for f in os.listdir(directory) if '_mask' not in f and f.endswith('.png')]\n\n    for img_name in image_files:\n        # Load image\n        img_path = os.path.join(directory, img_name)\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n        if img is None:\n            continue\n\n        # Resize image (e.g., to 256x256)\n        img = cv2.resize(img, (256, 256))\n        images.append(img)\n        labels.append(class_label)\n\n        # Load mask if applicable\n        if has_mask:\n            mask_name = img_name.replace('.png', '_mask.png')\n            mask_path = os.path.join(directory, mask_name)\n            if os.path.exists(mask_path):\n                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n                mask = cv2.resize(mask, (256, 256))\n                # Binarize mask (0 or 255)\n                mask = (mask > 0).astype(np.uint8) * 255\n                masks.append(mask)\n            else:\n                masks.append(np.zeros((256, 256), dtype=np.uint8))  # Empty mask if not found\n        else:\n            masks.append(np.zeros((256, 256), dtype=np.uint8))  # No mask for normal images\n\n    return images, masks, labels\n\n# Load data for each class\nnormal_images, normal_masks, normal_labels = load_images_and_masks(normal_dir, 'normal', has_mask=False)\nbenign_images, benign_masks, benign_labels = load_images_and_masks(benign_dir, 'benign', has_mask=True)\nmalignant_images, malignant_masks, malignant_labels = load_images_and_masks(malignant_dir, 'malignant', has_mask=True)\n\n# Combine all data\nall_images = normal_images + benign_images + malignant_images\nall_masks = normal_masks + benign_masks + malignant_masks\nall_labels = normal_labels + benign_labels + malignant_labels\n\n# Convert to numpy arrays\nall_images = np.array(all_images)\nall_masks = np.array(all_masks)\nall_labels = np.array(all_labels)\nprint(len(all_labels))\nprint(len(normal_masks))\nprint(len(benign_masks))\nprint(len(malignant_masks))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:34:40.620840Z","iopub.execute_input":"2025-07-30T04:34:40.621579Z","iopub.status.idle":"2025-07-30T04:34:44.817825Z","shell.execute_reply.started":"2025-07-30T04:34:40.621540Z","shell.execute_reply":"2025-07-30T04:34:44.817001Z"}},"outputs":[{"name":"stdout","text":"399\n64\n185\n150\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Normalize images and masks\nall_images = all_images / 255.0  # Normalize to [0, 1]\nall_masks = all_masks / 255.0    # Normalize to [0, 1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:36:41.650620Z","iopub.execute_input":"2025-07-30T04:36:41.650925Z","iopub.status.idle":"2025-07-30T04:36:41.790867Z","shell.execute_reply.started":"2025-07-30T04:36:41.650901Z","shell.execute_reply":"2025-07-30T04:36:41.790086Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Split data (80% train, 20% test)\nX_train, X_test, y_train, y_test, labels_train, labels_test = train_test_split(\n    all_images, all_masks, all_labels,\n    test_size=0.2, random_state=40, stratify=all_labels\n)\n\nX_val, X_test1, y_val, y_test1, labels_val, labels_test1 = train_test_split(\n    X_test, y_test, labels_test,\n    test_size=0.95, random_state=40, stratify=labels_test\n)\n\n\n# Reshape for deep learning models (add channel dimension)\nX_train = X_train[..., np.newaxis]  # Shape: (n_train, 256, 256, 1)\nX_test = X_test[..., np.newaxis]    # Shape: (n_test, 256, 256, 1)\nX_val = X_val[..., np.newaxis]    # Shape: (n_test, 256, 256, 1)\ny_train = y_train[..., np.newaxis]  # Shape: (n_train, 256, 256, 1)\ny_test = y_test[..., np.newaxis]    # Shape: (n_test, 256, 256, 1)\ny_val = y_val[..., np.newaxis]    # Shape: (n_test, 256, 256, 1)\n\nprint(f\"Training set: {X_train.shape}, {y_train.shape},{labels_train.shape}\")\nprint(f\"Testing set: {X_test.shape}, {y_test.shape},{labels_test.shape}\")\nprint(f\"Validation set: {X_val.shape}, {y_val.shape},{labels_val.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:36:42.064493Z","iopub.execute_input":"2025-07-30T04:36:42.064807Z","iopub.status.idle":"2025-07-30T04:36:42.229898Z","shell.execute_reply.started":"2025-07-30T04:36:42.064785Z","shell.execute_reply":"2025-07-30T04:36:42.229099Z"}},"outputs":[{"name":"stdout","text":"Training set: (319, 256, 256, 1), (319, 256, 256, 1),(319,)\nTesting set: (80, 256, 256, 1), (80, 256, 256, 1),(80,)\nValidation set: (4, 256, 256, 1), (4, 256, 256, 1),(4,)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from collections import Counter\n\nprint(\"Train label distribution:\", Counter(labels_train))\nprint(\"Test label distribution:\", Counter(labels_test))\n#print(\"Valdiation label distribution:\", Counter(labels_val))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:36:43.333119Z","iopub.execute_input":"2025-07-30T04:36:43.333391Z","iopub.status.idle":"2025-07-30T04:36:43.338529Z","shell.execute_reply.started":"2025-07-30T04:36:43.333369Z","shell.execute_reply":"2025-07-30T04:36:43.337601Z"}},"outputs":[{"name":"stdout","text":"Train label distribution: Counter({'benign': 148, 'malignant': 120, 'normal': 51})\nTest label distribution: Counter({'benign': 37, 'malignant': 30, 'normal': 13})\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"df_labels_train = pd.get_dummies(labels_train).astype(int)\ndf_labels_test = pd.get_dummies(labels_test).astype(int)\ndf_labels_val = pd.get_dummies(labels_val).astype(int)\n\n# Optional: reorder columns to follow a consistent order\n#df_labels = df_labels[['malignant', 'benign', 'normal']]  # reorder as needed\n\nprint(sum(df_labels_train['normal']))\ndf_labels_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:36:43.530926Z","iopub.execute_input":"2025-07-30T04:36:43.531208Z","iopub.status.idle":"2025-07-30T04:36:43.562226Z","shell.execute_reply.started":"2025-07-30T04:36:43.531187Z","shell.execute_reply":"2025-07-30T04:36:43.561635Z"}},"outputs":[{"name":"stdout","text":"51\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   benign  malignant  normal\n0       0          1       0\n1       1          0       0\n2       1          0       0\n3       1          0       0\n4       0          1       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>benign</th>\n      <th>malignant</th>\n      <th>normal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import albumentations as A\n\n# Define augmentation pipeline\naugmentation = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.Rotate(limit=10, p=0.5),\n    A.RandomBrightnessContrast(p=0.3),\n    A.RandomCrop(height=224, width=224, p=0.3),\n    A.Resize(256, 256)  # Ensure output size\n])\n\n# Apply augmentation to training data\naugmented_images = []\naugmented_masks = []\naugmented_labels = []\ndf_labels_train_np=np.array(df_labels_train)\nfor img, mask,label in zip(X_train, y_train,df_labels_train_np):\n    aug = augmentation(image=img.squeeze(), mask=mask.squeeze())\n    augmented_images.append(aug['image'][..., np.newaxis])\n    augmented_masks.append(aug['mask'][..., np.newaxis])\n    augmented_labels.append(label)\n    \n# Convert to numpy arrays\naugmented_images = np.array(augmented_images)\naugmented_masks = np.array(augmented_masks)\naugmented_labels=np.array(augmented_labels)\nprint(df_labels_train.shape)\nprint(augmented_labels.shape)\n# Combine original and augmented data\nX_train_aug = np.concatenate([X_train, augmented_images], axis=0)\ny_train_aug = np.concatenate([y_train, augmented_masks], axis=0)\ndf_labels_train_aug=np.concatenate([df_labels_train, augmented_labels], axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:36:44.703937Z","iopub.execute_input":"2025-07-30T04:36:44.704471Z","iopub.status.idle":"2025-07-30T04:36:50.089057Z","shell.execute_reply.started":"2025-07-30T04:36:44.704446Z","shell.execute_reply":"2025-07-30T04:36:50.088201Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"},{"name":"stdout","text":"(319, 3)\n(319, 3)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(f\"Training set: {X_train_aug.shape}, {y_train_aug.shape},{df_labels_train_aug.shape}\")\nprint(f\"Testing set: {X_test.shape}, {y_test.shape},{labels_test.shape}\")\nprint(f\"Validation set: {X_val.shape}, {y_val.shape},{labels_val.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:36:50.090340Z","iopub.execute_input":"2025-07-30T04:36:50.090930Z","iopub.status.idle":"2025-07-30T04:36:50.097622Z","shell.execute_reply.started":"2025-07-30T04:36:50.090911Z","shell.execute_reply":"2025-07-30T04:36:50.096627Z"}},"outputs":[{"name":"stdout","text":"Training set: (638, 256, 256, 1), (638, 256, 256, 1),(638, 3)\nTesting set: (80, 256, 256, 1), (80, 256, 256, 1),(80,)\nValidation set: (4, 256, 256, 1), (4, 256, 256, 1),(4,)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def dice_bce_loss(y_true, y_pred, axis=(1, 2, 3), smooth=1e-4):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred_sigmoid = tf.keras.activations.sigmoid(y_pred)  # Optional: if logits\n\n    # Binary cross-entropy\n    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred_sigmoid)\n\n    # Dice loss\n    y_pred_bin = tf.cast(y_pred_sigmoid > 0.5, tf.float32)\n    tp = tf.reduce_sum(y_true * y_pred_bin, axis=axis)\n    fn = tf.reduce_sum(y_true * (1 - y_pred_bin), axis=axis)\n    fp = tf.reduce_sum((1 - y_true) * y_pred_bin, axis=axis)\n    dice_score = (2 * tp + smooth) / (2 * tp + fn + fp + smooth)\n    dice_loss = 1.0 - tf.reduce_mean(dice_score)\n\n    # Combine\n    return dice_loss + tf.reduce_mean(bce)\n\ndef dice_loss(y_true, y_pred, axis=(1, 2, 3), smooth=1e-4):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred_sigmoid = tf.keras.activations.sigmoid(y_pred)  # Optional: if logits\n\n    # Dice loss\n    y_pred_bin = tf.cast(y_pred_sigmoid > 0.5, tf.float32)\n    tp = tf.reduce_sum(y_true * y_pred_bin, axis=axis)\n    fn = tf.reduce_sum(y_true * (1 - y_pred_bin), axis=axis)\n    fp = tf.reduce_sum((1 - y_true) * y_pred_bin, axis=axis)\n    dice_score = (2 * tp + smooth) / (2 * tp + fn + fp + smooth)\n    dice_loss = 1.0 - tf.reduce_mean(dice_score)\n    return dice_loss \n\ndef dice(y_true, y_pred, axis=(0, 1, 2), smooth=0.0001, thr=0.5):\n    y_true = tf.cast(y_true, tf.float32) # (B, H, W, C)\n    y_pred = tf.cast(y_pred > thr, tf.float32) # (B, H, W, C)\n    tp = tf.math.reduce_sum(y_true * y_pred, axis=axis) # calculate True Positive\n    fn = tf.math.reduce_sum(y_true * (1 - y_pred), axis=axis) # calculate False Negative\n    fp = tf.math.reduce_sum((1 - y_true) * y_pred, axis=axis) # calculate False Positive\n    dice = (2*tp + smooth) / (2*tp + fn + fp + smooth) # calculate Dice score\n    dice = tf.math.reduce_mean(dice) # average over all classes\n    return dice # Dice loss is 1 - Dice score\n\ndef iou(y_true, y_pred, axis=(0, 1, 2), smooth=0.0001, thr=0.5):\n    y_true = tf.cast(y_true, tf.float32) # (B, H, W, C)\n    y_pred = tf.cast(y_pred > thr, tf.float32) # (B, H, W, C)\n    tp = tf.math.reduce_sum(y_true * y_pred, axis=axis) # calculate True Positive\n    fn = tf.math.reduce_sum(y_true * (1 - y_pred), axis=axis) # calculate False Negative\n    fp = tf.math.reduce_sum((1 - y_true) * y_pred, axis=axis) # calculate False Positive\n    iou = (tp + smooth) / (tp + fn + fp + smooth) # calculate Dice score\n    iou = tf.math.reduce_mean(iou) # average over all classes\n    return iou # Dice loss is 1 - Dice score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:36:50.098520Z","iopub.execute_input":"2025-07-30T04:36:50.098831Z","iopub.status.idle":"2025-07-30T04:36:50.116367Z","shell.execute_reply.started":"2025-07-30T04:36:50.098805Z","shell.execute_reply":"2025-07-30T04:36:50.115621Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# #Basic U-Nnet\n\n# def model_seg_class(inp_size=(256,256,1),filter_size=32):\n\n#     inp=layers.Input(inp_size)\n#     #stage 1\n#     x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(inp)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     c4=x\n#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    \n#     #stage 2\n#     x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     c3=x\n#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    \n#     #stage 3\n#     x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     c2=x\n#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    \n#     #stage 4\n#     x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     c1=x\n#     p1=x\n#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n\n#     #stage 5\n#     x = layers.Conv2D(filter_size*16, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*16, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*16, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     p2=x\n#     x = layers.UpSampling2D(size=(2, 2))(x)\n\n#     #stage 6\n#     x=layers.concatenate([c1, x], axis=3)\n#     x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     p3=x\n#     x = layers.UpSampling2D(size=(2, 2))(x)\n\n#     #stage 7\n#     x=layers.concatenate([c2, x], axis=3)\n#     x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.UpSampling2D(size=(2, 2))(x)\n\n#     #stage 8\n#     x=layers.concatenate([c3, x], axis=3)\n#     x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.UpSampling2D(size=(2, 2))(x)\n\n#     #stage 9\n#     x=layers.concatenate([c4, x], axis=3)\n#     x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(1, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     seg_out=layers.Activation('sigmoid',name='seg_out')(x)\n    \n#     #classifier\n#     p1=layers.Conv2D(1,(3,3),padding='same',activation='relu')(p1)\n#     p2=layers.Conv2D(1,(3,3),padding='same',activation='relu')(p2)\n#     p3=layers.Conv2D(1,(3,3),padding='same',activation='relu')(p3)\n#     g1 = layers.GlobalAveragePooling2D()(p1)\n#     g2 = layers.GlobalAveragePooling2D()(p2)\n#     g3 = layers.GlobalAveragePooling2D()(p3)\n#     x=layers.concatenate([g1,g2,g3])\n#     x=layers.Dense(32,activation='relu')(x)\n#     cls_out=layers.Dense(3,activation='softmax',name='cls_out')(x)\n\n    \n    \n#     model = Model(inputs=inp, outputs=[seg_out,cls_out])\n#     return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#With Gate units\ndef gate_unit(inp,size):\n    x = layers.Conv2D(size, (3,3), activation=None, padding='same')(inp)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('sigmoid')(x)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Reshape((1, 1, size))(x)\n    g1=layers.Multiply()([x,inp])\n    x = layers.Conv2D(size, (3,3), activation=None, padding='same')(inp)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('sigmoid')(x)\n    x = layers.GlobalMaxPooling2D()(x)\n    x = layers.Reshape((1, 1, size))(x)\n    g2=layers.Multiply()([x,inp])\n    x=layers.add([g1,g2])\n    x = layers.Conv2D(size, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    return x\n\ndef model_seg_class(inp_size=(256,256,1),filter_size=32):\n\n    inp=layers.Input(inp_size)\n    #stage 1\n    x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(inp)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    # x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n    # x = layers.BatchNormalization()(x)\n    # x = layers.Activation('relu')(x)\n    c4=x\n    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    \n    #stage 2\n    x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    c3=x\n    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    \n    #stage 3\n    x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    c2=x\n    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    \n    #stage 4\n    x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    c1=x\n    p1=x\n    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n\n    #stage 5\n    x = layers.Conv2D(filter_size*16, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*16, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*16, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    p2=x\n    x = layers.UpSampling2D(size=(2, 2))(x)\n\n    #stage 6\n    c1=gate_unit(c1,filter_size*8)\n    x=layers.concatenate([c1, x], axis=3)\n    x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    # x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n    # x = layers.BatchNormalization()(x)\n    # x = layers.Activation('relu')(x)\n    p3=x\n    x = layers.UpSampling2D(size=(2, 2))(x)\n\n    #stage 7\n    c2=gate_unit(c2,filter_size*4)\n    x=layers.concatenate([c2, x], axis=3)\n    x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    # x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n    # x = layers.BatchNormalization()(x)\n    # x = layers.Activation('relu')(x)\n    x = layers.UpSampling2D(size=(2, 2))(x)\n\n    #stage 8\n    c3=gate_unit(c3,filter_size*2)\n    x=layers.concatenate([c3, x], axis=3)\n    x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    # x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    # x = layers.BatchNormalization()(x)\n    # x = layers.Activation('relu')(x)\n    x = layers.UpSampling2D(size=(2, 2))(x)\n\n    #stage 9\n    c4=gate_unit(c4,filter_size)\n    x=layers.concatenate([c4, x], axis=3)\n    x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(1, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    seg_out=layers.Activation('sigmoid',name='seg_out')(x)\n    \n    #classifier\n    p1=layers.Conv2D(1,(3,3),padding='same',activation='relu')(p1)\n    p2=layers.Conv2D(1,(3,3),padding='same',activation='relu')(p2)\n    p3=layers.Conv2D(1,(3,3),padding='same',activation='relu')(p3)\n    g1 = layers.GlobalAveragePooling2D()(p1)\n    g2 = layers.GlobalAveragePooling2D()(p2)\n    g3 = layers.GlobalAveragePooling2D()(p3)\n    x=layers.concatenate([g1,g2,g3])\n    x=layers.Dense(32,activation='relu')(x)\n    cls_out=layers.Dense(3,activation='softmax',name='cls_out')(x)\n\n    \n    \n    model = Model(inputs=inp, outputs=[seg_out,cls_out])\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:09:38.830616Z","iopub.execute_input":"2025-07-29T15:09:38.830937Z","iopub.status.idle":"2025-07-29T15:09:38.855948Z","shell.execute_reply.started":"2025-07-29T15:09:38.830911Z","shell.execute_reply":"2025-07-29T15:09:38.855148Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# #With attention gates\n# def gate_unit(inp,size):\n#     x = layers.Conv2D(size, (3,3), activation=None, padding='same')(inp)\n#     x = layers.Activation('relu')(x)\n#     x = layers.GlobalAveragePooling2D()(x)\n#     x = layers.Reshape((1, 1, size))(x)\n#     g1=layers.Multiply()([x,inp])\n#     x = layers.Conv2D(size, (3,3), activation=None, padding='same')(inp)\n#     x = layers.Activation('relu')(x)\n#     x = layers.GlobalMaxPooling2D()(x)\n#     x = layers.Reshape((1, 1, size))(x)\n#     g2=layers.Multiply()([x,inp])\n#     x=layers.add([g1,g2])\n#     x = layers.Conv2D(size, (3,3), activation=None, padding='same')(x)\n#     x = layers.Activation('relu')(x)\n#     return x\n    \n    \n# def model_seg_class(inp_size=(256,256,1),filter_size=32):\n\n#     inp=layers.Input(inp_size)\n#     #stage 1\n#     x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(inp)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     c4=x\n#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    \n#     #stage 2\n#     x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     c3=x\n#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    \n#     #stage 3\n#     x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     c2=x\n#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    \n#     #stage 4\n#     x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     c1=x\n#     p1=x\n#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n\n#     #stage 5\n#     x = layers.Conv2D(filter_size*16, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*16, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*16, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     p2=x\n#     x = layers.UpSampling2D(size=(2, 2))(x)\n\n#     #stage 6\n#     g1 = gate_unit(c1,filter_size*8)\n#     x = layers.concatenate([g1, x], axis=3)   \n#     # c1 = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(c1)\n#     # c1 = layers.BatchNormalization()(c1)\n#     # c1 = layers.Activation('relu')(c1)\n#     # x = layers.concatenate([c1, x], axis=3) \n#     x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     p3=x\n#     x = layers.UpSampling2D(size=(2, 2))(x)\n\n#     #stage 7\n#     g2 = gate_unit(c2,filter_size*4)\n#     x = layers.concatenate([g2, x], axis=3)\n#     # c2 = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(c2)\n#     # c2 = layers.BatchNormalization()(c2)\n#     # c2 = layers.Activation('relu')(c2)\n#     # x=layers.concatenate([c2, x], axis=3)\n#     x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.UpSampling2D(size=(2, 2))(x)\n\n#     #stage 8\n#     g3 = gate_unit(c3,filter_size*2)\n#     x = layers.concatenate([g3, x], axis=3)\n#     # c3 = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(c3)\n#     # c3 = layers.BatchNormalization()(c3)\n#     # c3 = layers.Activation('relu')(c3)\n#     # x=layers.concatenate([c3, x], axis=3)\n#     x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.UpSampling2D(size=(2, 2))(x)\n\n#     #stage 9\n#     g4 = gate_unit(c4,filter_size)\n#     x = layers.concatenate([g4, x], axis=3)\n#     # c4 = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(c4)\n#     # c4 = layers.BatchNormalization()(c4)\n#     # c4 = layers.Activation('relu')(c4)\n#     # x=layers.concatenate([c4, x], axis=3)\n#     x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Conv2D(1, (3,3), activation=None, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     seg_out=layers.Activation('sigmoid',name='seg_out')(x)\n    \n#     #classifier\n#     p1=layers.Conv2D(1,(3,3),padding='same',activation='relu')(p1)\n#     p2=layers.Conv2D(1,(3,3),padding='same',activation='relu')(p2)\n#     p3=layers.Conv2D(1,(3,3),padding='same',activation='relu')(p3)\n#     g1 = layers.GlobalAveragePooling2D()(p1)\n#     g2 = layers.GlobalAveragePooling2D()(p2)\n#     g3 = layers.GlobalAveragePooling2D()(p3)\n#     x=layers.concatenate([g1,g2,g3])\n#     x=layers.Dense(32,activation='relu')(x)\n#     cls_out=layers.Dense(3,activation='softmax',name='cls_out')(x)\n\n    \n    \n#     model = Model(inputs=inp, outputs=[seg_out,cls_out])\n#     return model","metadata":{"trusted":true},"outputs":[],"execution_count":36},{"cell_type":"code","source":"#UNET ++\n\ndef model_seg_class(inp_size=(256,256,1),filter_size=16):\n\n    inp=layers.Input(inp_size)\n    #stage 0,0\n    x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(inp)\n    x = layers.BatchNormalization()(x)    \n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    # x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n    # x = layers.BatchNormalization()(x)\n    # x = layers.Activation('relu')(x)\n    s00=x\n    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    \n    #stage 1,0\n    x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    # x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    # x = layers.BatchNormalization()(x)\n    # x = layers.Activation('relu')(x)\n    s10=x\n    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    \n    #stage 2,0\n    x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    # x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n    # x = layers.BatchNormalization()(x)\n    # x = layers.Activation('relu')(x)\n    s20=x\n    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    \n    #stage 3,0\n    x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    s30=x\n    p1=x\n    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    s30_mp=x\n\n    #stage 0,1\n    x = layers.concatenate([s00, layers.UpSampling2D(size=(2, 2))(s10)], axis=3) \n    x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    s01=x\n\n    #stage 1,1\n    x = layers.concatenate([s10, layers.UpSampling2D(size=(2, 2))(s20)], axis=3) \n    x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    s11=x\n\n    #stage 0,2\n    x = layers.concatenate([s01,s00, layers.UpSampling2D(size=(2, 2))(s11)], axis=3) \n    x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    s02=x\n\n    #stage 2,1\n    x = layers.concatenate([s20,layers.UpSampling2D(size=(2, 2))(s30)], axis=3) \n    x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    s21=x\n\n    #stage 1,2\n    x = layers.concatenate([s11,s10,layers.UpSampling2D(size=(2, 2))(s21)], axis=3) \n    x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    s12=x\n\n    #stage 0,3\n    x = layers.concatenate([s00,s01,s02,layers.UpSampling2D(size=(2, 2))(s12)], axis=3) \n    x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    s03=x\n    \n\n    #stage 4,0\n    x = layers.Conv2D(filter_size*16, (3,3), activation=None, padding='same')(s30_mp)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*16, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*16, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    p2=x\n    s40=x\n    x = layers.UpSampling2D(size=(2, 2))(x)\n\n    #stage 3,1\n    x = layers.concatenate([x,s30], axis=3) \n    x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*8, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    p3=x\n    x = layers.UpSampling2D(size=(2, 2))(x)\n\n    #stage 2,2\n    x = layers.concatenate([x,s20,s21], axis=3) \n    x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*4, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.UpSampling2D(size=(2, 2))(x)\n\n    #stage 1,3\n    x = layers.concatenate([x,s10,s11,s12], axis=3) \n    x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(filter_size*2, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.UpSampling2D(size=(2, 2))(x)\n\n    #stage 0,4\n    x = layers.concatenate([x,s00,s01,s02,s03], axis=3) \n    x = layers.Conv2D(filter_size, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(1, (3,3), activation=None, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    seg_out=layers.Activation('sigmoid',name='seg_out')(x)\n    \n    #classifier\n    p1=layers.Conv2D(1,(3,3),padding='same',activation='relu')(p1)\n    p2=layers.Conv2D(1,(3,3),padding='same',activation='relu')(p2)\n    p3=layers.Conv2D(1,(3,3),padding='same',activation='relu')(p3)\n    g1 = layers.GlobalAveragePooling2D()(p1)\n    g2 = layers.GlobalAveragePooling2D()(p2)\n    g3 = layers.GlobalAveragePooling2D()(p3)\n    x=layers.concatenate([g1,g2,g3])\n    x=layers.Dense(32,activation='relu')(x)\n    cls_out=layers.Dense(3,activation='softmax',name='cls_out')(x)\n\n    \n    \n    model = Model(inputs=inp, outputs=[seg_out,cls_out])\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T14:01:33.338698Z","iopub.execute_input":"2025-07-29T14:01:33.339453Z","iopub.status.idle":"2025-07-29T14:01:33.367516Z","shell.execute_reply.started":"2025-07-29T14:01:33.339424Z","shell.execute_reply":"2025-07-29T14:01:33.366778Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"model=model_seg_class()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:10:06.540701Z","iopub.execute_input":"2025-07-29T15:10:06.541003Z","iopub.status.idle":"2025-07-29T15:10:07.069617Z","shell.execute_reply.started":"2025-07-29T15:10:06.540983Z","shell.execute_reply":"2025-07-29T15:10:07.069015Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss={\n        'seg_out': dice_bce_loss,\n        'cls_out': 'CategoricalCrossentropy'\n    },\n    metrics={\n        'seg_out': [dice], # You might use Dice Coefficient or IoU here\n        'cls_out': ['accuracy']\n    }\n)\n\ncheckpoint_cb = ModelCheckpoint(\n    filepath=\"/kaggle/working/best_model.h5\",\n    monitor=\"val_seg_out_dice\",        # or \"val_dice\" or \"val_iou\"\n    mode=\"max\",                # \"min\" for losses, \"max\" for accuracy metrics\n    save_best_only=True,\n    verbose=1\n)\n\n\nstart=time.time()\nhistory = model.fit(\n    x=X_train_aug,\n    y={'seg_out': y_train_aug, 'cls_out': df_labels_train_aug},\n    batch_size=16,\n    epochs=200,\n    validation_data=(X_test, {'seg_out': y_test, 'cls_out': df_labels_test}),\n    callbacks=[checkpoint_cb]\n)\n\nend=time.time()\nprint(f\"\\n\\nTraining time: {(end-start):.2f} seconds\")\nmodel.save('/kaggle/working/unet.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T16:15:37.167117Z","iopub.execute_input":"2025-07-29T16:15:37.167868Z","iopub.status.idle":"2025-07-29T17:05:15.007668Z","shell.execute_reply.started":"2025-07-29T16:15:37.167847Z","shell.execute_reply":"2025-07-29T17:05:15.006665Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830ms/step - cls_out_accuracy: 0.9916 - cls_out_loss: 0.0267 - loss: 1.7665 - seg_out_dice: 0.6854 - seg_out_loss: 1.7398\nEpoch 1: val_seg_out_dice improved from -inf to 0.55875, saving model to /kaggle/working/best_model.h5\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 981ms/step - cls_out_accuracy: 0.9915 - cls_out_loss: 0.0272 - loss: 1.7674 - seg_out_dice: 0.6846 - seg_out_loss: 1.7402 - val_cls_out_accuracy: 0.8375 - val_cls_out_loss: 1.0872 - val_loss: 2.8921 - val_seg_out_dice: 0.5588 - val_seg_out_loss: 1.8050\nEpoch 2/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - cls_out_accuracy: 0.9720 - cls_out_loss: 0.0703 - loss: 1.8226 - seg_out_dice: 0.6273 - seg_out_loss: 1.7523\nEpoch 2: val_seg_out_dice did not improve from 0.55875\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 519ms/step - cls_out_accuracy: 0.9721 - cls_out_loss: 0.0703 - loss: 1.8227 - seg_out_dice: 0.6273 - seg_out_loss: 1.7524 - val_cls_out_accuracy: 0.8000 - val_cls_out_loss: 1.0903 - val_loss: 2.9178 - val_seg_out_dice: 0.4637 - val_seg_out_loss: 1.8275\nEpoch 3/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - cls_out_accuracy: 0.9860 - cls_out_loss: 0.0460 - loss: 1.7935 - seg_out_dice: 0.6609 - seg_out_loss: 1.7475\nEpoch 3: val_seg_out_dice did not improve from 0.55875\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 516ms/step - cls_out_accuracy: 0.9861 - cls_out_loss: 0.0457 - loss: 1.7934 - seg_out_dice: 0.6612 - seg_out_loss: 1.7477 - val_cls_out_accuracy: 0.7500 - val_cls_out_loss: 1.9325 - val_loss: 3.7589 - val_seg_out_dice: 0.4771 - val_seg_out_loss: 1.8265\nEpoch 4/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0071 - loss: 1.7745 - seg_out_dice: 0.6833 - seg_out_loss: 1.7674\nEpoch 4: val_seg_out_dice improved from 0.55875 to 0.57803, saving model to /kaggle/working/best_model.h5\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 516ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0072 - loss: 1.7742 - seg_out_dice: 0.6833 - seg_out_loss: 1.7671 - val_cls_out_accuracy: 0.7000 - val_cls_out_loss: 1.7898 - val_loss: 3.5934 - val_seg_out_dice: 0.5780 - val_seg_out_loss: 1.8036\nEpoch 5/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0016 - loss: 1.7585 - seg_out_dice: 0.6863 - seg_out_loss: 1.7569\nEpoch 5: val_seg_out_dice improved from 0.57803 to 0.61781, saving model to /kaggle/working/best_model.h5\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 514ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0016 - loss: 1.7585 - seg_out_dice: 0.6865 - seg_out_loss: 1.7568 - val_cls_out_accuracy: 0.7875 - val_cls_out_loss: 0.9910 - val_loss: 2.7944 - val_seg_out_dice: 0.6178 - val_seg_out_loss: 1.8033\nEpoch 6/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0021 - loss: 1.7507 - seg_out_dice: 0.7004 - seg_out_loss: 1.7486\nEpoch 6: val_seg_out_dice improved from 0.61781 to 0.62850, saving model to /kaggle/working/best_model.h5\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 520ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0021 - loss: 1.7508 - seg_out_dice: 0.7001 - seg_out_loss: 1.7488 - val_cls_out_accuracy: 0.7375 - val_cls_out_loss: 1.3473 - val_loss: 3.1512 - val_seg_out_dice: 0.6285 - val_seg_out_loss: 1.8039\nEpoch 7/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0015 - loss: 1.7578 - seg_out_dice: 0.7148 - seg_out_loss: 1.7563\nEpoch 7: val_seg_out_dice improved from 0.62850 to 0.63181, saving model to /kaggle/working/best_model.h5\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 524ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0015 - loss: 1.7577 - seg_out_dice: 0.7150 - seg_out_loss: 1.7563 - val_cls_out_accuracy: 0.7875 - val_cls_out_loss: 1.2921 - val_loss: 3.0985 - val_seg_out_dice: 0.6318 - val_seg_out_loss: 1.8064\nEpoch 8/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9992 - cls_out_loss: 0.0048 - loss: 1.7447 - seg_out_dice: 0.7248 - seg_out_loss: 1.7398\nEpoch 8: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9991 - cls_out_loss: 0.0050 - loss: 1.7452 - seg_out_dice: 0.7244 - seg_out_loss: 1.7402 - val_cls_out_accuracy: 0.6250 - val_cls_out_loss: 2.4879 - val_loss: 4.2907 - val_seg_out_dice: 0.5205 - val_seg_out_loss: 1.8028\nEpoch 9/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9902 - cls_out_loss: 0.0172 - loss: 1.7628 - seg_out_dice: 0.6907 - seg_out_loss: 1.7456\nEpoch 9: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9901 - cls_out_loss: 0.0176 - loss: 1.7634 - seg_out_dice: 0.6909 - seg_out_loss: 1.7458 - val_cls_out_accuracy: 0.5125 - val_cls_out_loss: 5.3845 - val_loss: 7.1969 - val_seg_out_dice: 0.5274 - val_seg_out_loss: 1.8124\nEpoch 10/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9607 - cls_out_loss: 0.1124 - loss: 1.8586 - seg_out_dice: 0.6456 - seg_out_loss: 1.7462\nEpoch 10: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9605 - cls_out_loss: 0.1133 - loss: 1.8597 - seg_out_dice: 0.6458 - seg_out_loss: 1.7464 - val_cls_out_accuracy: 0.6375 - val_cls_out_loss: 2.2135 - val_loss: 4.0265 - val_seg_out_dice: 0.5187 - val_seg_out_loss: 1.8130\nEpoch 11/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - cls_out_accuracy: 0.9514 - cls_out_loss: 0.1712 - loss: 1.9385 - seg_out_dice: 0.6166 - seg_out_loss: 1.7673\nEpoch 11: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 504ms/step - cls_out_accuracy: 0.9519 - cls_out_loss: 0.1692 - loss: 1.9362 - seg_out_dice: 0.6167 - seg_out_loss: 1.7670 - val_cls_out_accuracy: 0.6875 - val_cls_out_loss: 4.2287 - val_loss: 6.0858 - val_seg_out_dice: 0.3567 - val_seg_out_loss: 1.8571\nEpoch 12/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - cls_out_accuracy: 0.9882 - cls_out_loss: 0.0320 - loss: 1.7928 - seg_out_dice: 0.6426 - seg_out_loss: 1.7608\nEpoch 12: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9882 - cls_out_loss: 0.0320 - loss: 1.7927 - seg_out_dice: 0.6427 - seg_out_loss: 1.7607 - val_cls_out_accuracy: 0.6750 - val_cls_out_loss: 3.5720 - val_loss: 5.3860 - val_seg_out_dice: 0.5300 - val_seg_out_loss: 1.8140\nEpoch 13/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9929 - cls_out_loss: 0.0119 - loss: 1.7794 - seg_out_dice: 0.6737 - seg_out_loss: 1.7675\nEpoch 13: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9929 - cls_out_loss: 0.0120 - loss: 1.7792 - seg_out_dice: 0.6738 - seg_out_loss: 1.7672 - val_cls_out_accuracy: 0.7750 - val_cls_out_loss: 1.8677 - val_loss: 3.6705 - val_seg_out_dice: 0.6128 - val_seg_out_loss: 1.8027\nEpoch 14/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - cls_out_accuracy: 0.9989 - cls_out_loss: 0.0057 - loss: 1.7557 - seg_out_dice: 0.7002 - seg_out_loss: 1.7500\nEpoch 14: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9988 - cls_out_loss: 0.0058 - loss: 1.7559 - seg_out_dice: 0.7001 - seg_out_loss: 1.7501 - val_cls_out_accuracy: 0.7500 - val_cls_out_loss: 1.6040 - val_loss: 3.4071 - val_seg_out_dice: 0.6141 - val_seg_out_loss: 1.8030\nEpoch 15/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - cls_out_accuracy: 0.9991 - cls_out_loss: 0.0052 - loss: 1.7711 - seg_out_dice: 0.6960 - seg_out_loss: 1.7659\nEpoch 15: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 509ms/step - cls_out_accuracy: 0.9991 - cls_out_loss: 0.0053 - loss: 1.7709 - seg_out_dice: 0.6961 - seg_out_loss: 1.7656 - val_cls_out_accuracy: 0.7375 - val_cls_out_loss: 1.1774 - val_loss: 2.9809 - val_seg_out_dice: 0.6154 - val_seg_out_loss: 1.8035\nEpoch 16/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - cls_out_accuracy: 0.9920 - cls_out_loss: 0.0548 - loss: 1.8084 - seg_out_dice: 0.7203 - seg_out_loss: 1.7536\nEpoch 16: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9918 - cls_out_loss: 0.0556 - loss: 1.8093 - seg_out_dice: 0.7196 - seg_out_loss: 1.7536 - val_cls_out_accuracy: 0.6250 - val_cls_out_loss: 2.9909 - val_loss: 4.7949 - val_seg_out_dice: 0.5560 - val_seg_out_loss: 1.8040\nEpoch 17/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9937 - cls_out_loss: 0.0287 - loss: 1.7682 - seg_out_dice: 0.6673 - seg_out_loss: 1.7395\nEpoch 17: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9936 - cls_out_loss: 0.0288 - loss: 1.7686 - seg_out_dice: 0.6673 - seg_out_loss: 1.7399 - val_cls_out_accuracy: 0.8125 - val_cls_out_loss: 1.0174 - val_loss: 2.8214 - val_seg_out_dice: 0.5731 - val_seg_out_loss: 1.8039\nEpoch 18/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9973 - cls_out_loss: 0.0112 - loss: 1.7664 - seg_out_dice: 0.6639 - seg_out_loss: 1.7552\nEpoch 18: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9973 - cls_out_loss: 0.0112 - loss: 1.7664 - seg_out_dice: 0.6647 - seg_out_loss: 1.7552 - val_cls_out_accuracy: 0.7500 - val_cls_out_loss: 1.3339 - val_loss: 3.1367 - val_seg_out_dice: 0.5351 - val_seg_out_loss: 1.8028\nEpoch 19/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9976 - cls_out_loss: 0.0062 - loss: 1.7689 - seg_out_dice: 0.6890 - seg_out_loss: 1.7627\nEpoch 19: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9974 - cls_out_loss: 0.0066 - loss: 1.7691 - seg_out_dice: 0.6892 - seg_out_loss: 1.7625 - val_cls_out_accuracy: 0.7125 - val_cls_out_loss: 1.8971 - val_loss: 3.7000 - val_seg_out_dice: 0.4914 - val_seg_out_loss: 1.8029\nEpoch 20/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9950 - cls_out_loss: 0.0172 - loss: 1.7671 - seg_out_dice: 0.7067 - seg_out_loss: 1.7499\nEpoch 20: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9949 - cls_out_loss: 0.0175 - loss: 1.7674 - seg_out_dice: 0.7066 - seg_out_loss: 1.7500 - val_cls_out_accuracy: 0.7125 - val_cls_out_loss: 1.2968 - val_loss: 3.1022 - val_seg_out_dice: 0.6201 - val_seg_out_loss: 1.8054\nEpoch 21/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9930 - cls_out_loss: 0.0158 - loss: 1.7670 - seg_out_dice: 0.7291 - seg_out_loss: 1.7512\nEpoch 21: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9930 - cls_out_loss: 0.0159 - loss: 1.7672 - seg_out_dice: 0.7279 - seg_out_loss: 1.7513 - val_cls_out_accuracy: 0.6750 - val_cls_out_loss: 2.0873 - val_loss: 3.8930 - val_seg_out_dice: 0.6028 - val_seg_out_loss: 1.8056\nEpoch 22/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0063 - loss: 1.7665 - seg_out_dice: 0.6852 - seg_out_loss: 1.7602\nEpoch 22: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0063 - loss: 1.7663 - seg_out_dice: 0.6854 - seg_out_loss: 1.7600 - val_cls_out_accuracy: 0.7875 - val_cls_out_loss: 1.0535 - val_loss: 2.8580 - val_seg_out_dice: 0.5875 - val_seg_out_loss: 1.8045\nEpoch 23/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0027 - loss: 1.7652 - seg_out_dice: 0.7305 - seg_out_loss: 1.7624\nEpoch 23: val_seg_out_dice did not improve from 0.63181\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0027 - loss: 1.7649 - seg_out_dice: 0.7303 - seg_out_loss: 1.7622 - val_cls_out_accuracy: 0.7625 - val_cls_out_loss: 1.1901 - val_loss: 2.9924 - val_seg_out_dice: 0.6064 - val_seg_out_loss: 1.8023\nEpoch 24/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0050 - loss: 1.7420 - seg_out_dice: 0.7263 - seg_out_loss: 1.7370\nEpoch 24: val_seg_out_dice improved from 0.63181 to 0.63884, saving model to /kaggle/working/best_model.h5\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 519ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0050 - loss: 1.7423 - seg_out_dice: 0.7264 - seg_out_loss: 1.7373 - val_cls_out_accuracy: 0.7625 - val_cls_out_loss: 1.1956 - val_loss: 2.9996 - val_seg_out_dice: 0.6388 - val_seg_out_loss: 1.8040\nEpoch 25/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0031 - loss: 1.7370 - seg_out_dice: 0.7411 - seg_out_loss: 1.7339\nEpoch 25: val_seg_out_dice improved from 0.63884 to 0.64021, saving model to /kaggle/working/best_model.h5\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 518ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0031 - loss: 1.7375 - seg_out_dice: 0.7403 - seg_out_loss: 1.7344 - val_cls_out_accuracy: 0.7375 - val_cls_out_loss: 1.4133 - val_loss: 3.2191 - val_seg_out_dice: 0.6402 - val_seg_out_loss: 1.8058\nEpoch 26/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 5.7616e-04 - loss: 1.7746 - seg_out_dice: 0.7142 - seg_out_loss: 1.7740\nEpoch 26: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 5.7521e-04 - loss: 1.7741 - seg_out_dice: 0.7146 - seg_out_loss: 1.7735 - val_cls_out_accuracy: 0.7250 - val_cls_out_loss: 1.3886 - val_loss: 3.1922 - val_seg_out_dice: 0.6255 - val_seg_out_loss: 1.8036\nEpoch 27/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 9.6224e-04 - loss: 1.7635 - seg_out_dice: 0.7529 - seg_out_loss: 1.7625\nEpoch 27: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 9.5674e-04 - loss: 1.7633 - seg_out_dice: 0.7527 - seg_out_loss: 1.7623 - val_cls_out_accuracy: 0.7250 - val_cls_out_loss: 1.3979 - val_loss: 3.2002 - val_seg_out_dice: 0.6350 - val_seg_out_loss: 1.8023\nEpoch 28/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - cls_out_accuracy: 0.9988 - cls_out_loss: 0.0033 - loss: 1.7532 - seg_out_dice: 0.7479 - seg_out_loss: 1.7499\nEpoch 28: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9988 - cls_out_loss: 0.0033 - loss: 1.7533 - seg_out_dice: 0.7477 - seg_out_loss: 1.7500 - val_cls_out_accuracy: 0.6250 - val_cls_out_loss: 1.5167 - val_loss: 3.3200 - val_seg_out_dice: 0.6263 - val_seg_out_loss: 1.8033\nEpoch 29/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - cls_out_accuracy: 0.9977 - cls_out_loss: 0.0108 - loss: 1.7644 - seg_out_dice: 0.7544 - seg_out_loss: 1.7536\nEpoch 29: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9978 - cls_out_loss: 0.0107 - loss: 1.7643 - seg_out_dice: 0.7538 - seg_out_loss: 1.7536 - val_cls_out_accuracy: 0.7000 - val_cls_out_loss: 2.9760 - val_loss: 4.7792 - val_seg_out_dice: 0.5919 - val_seg_out_loss: 1.8032\nEpoch 30/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9995 - cls_out_loss: 0.0029 - loss: 1.7604 - seg_out_dice: 0.7446 - seg_out_loss: 1.7575\nEpoch 30: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9995 - cls_out_loss: 0.0030 - loss: 1.7604 - seg_out_dice: 0.7446 - seg_out_loss: 1.7574 - val_cls_out_accuracy: 0.6500 - val_cls_out_loss: 2.2565 - val_loss: 4.0590 - val_seg_out_dice: 0.5918 - val_seg_out_loss: 1.8025\nEpoch 31/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9988 - cls_out_loss: 0.0062 - loss: 1.7600 - seg_out_dice: 0.7503 - seg_out_loss: 1.7539\nEpoch 31: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9986 - cls_out_loss: 0.0068 - loss: 1.7606 - seg_out_dice: 0.7500 - seg_out_loss: 1.7538 - val_cls_out_accuracy: 0.6750 - val_cls_out_loss: 4.1160 - val_loss: 5.9275 - val_seg_out_dice: 0.5475 - val_seg_out_loss: 1.8115\nEpoch 32/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9620 - cls_out_loss: 0.1722 - loss: 1.9192 - seg_out_dice: 0.6786 - seg_out_loss: 1.7470\nEpoch 32: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9620 - cls_out_loss: 0.1715 - loss: 1.9187 - seg_out_dice: 0.6784 - seg_out_loss: 1.7472 - val_cls_out_accuracy: 0.4625 - val_cls_out_loss: 15.2144 - val_loss: 17.0938 - val_seg_out_dice: 0.3011 - val_seg_out_loss: 1.8793\nEpoch 33/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9599 - cls_out_loss: 0.1339 - loss: 1.9004 - seg_out_dice: 0.6707 - seg_out_loss: 1.7665\nEpoch 33: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9599 - cls_out_loss: 0.1338 - loss: 1.9000 - seg_out_dice: 0.6708 - seg_out_loss: 1.7662 - val_cls_out_accuracy: 0.6500 - val_cls_out_loss: 3.8053 - val_loss: 5.6401 - val_seg_out_dice: 0.4124 - val_seg_out_loss: 1.8348\nEpoch 34/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9854 - cls_out_loss: 0.0347 - loss: 1.7788 - seg_out_dice: 0.7070 - seg_out_loss: 1.7441\nEpoch 34: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9855 - cls_out_loss: 0.0345 - loss: 1.7788 - seg_out_dice: 0.7068 - seg_out_loss: 1.7443 - val_cls_out_accuracy: 0.7125 - val_cls_out_loss: 1.2469 - val_loss: 3.0506 - val_seg_out_dice: 0.5869 - val_seg_out_loss: 1.8038\nEpoch 35/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0071 - loss: 1.7477 - seg_out_dice: 0.7102 - seg_out_loss: 1.7406\nEpoch 35: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0071 - loss: 1.7480 - seg_out_dice: 0.7105 - seg_out_loss: 1.7409 - val_cls_out_accuracy: 0.7750 - val_cls_out_loss: 0.9376 - val_loss: 2.7410 - val_seg_out_dice: 0.5968 - val_seg_out_loss: 1.8034\nEpoch 36/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - cls_out_accuracy: 0.9942 - cls_out_loss: 0.0113 - loss: 1.7636 - seg_out_dice: 0.7292 - seg_out_loss: 1.7523\nEpoch 36: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9942 - cls_out_loss: 0.0114 - loss: 1.7637 - seg_out_dice: 0.7290 - seg_out_loss: 1.7523 - val_cls_out_accuracy: 0.6000 - val_cls_out_loss: 1.8351 - val_loss: 3.6380 - val_seg_out_dice: 0.5394 - val_seg_out_loss: 1.8028\nEpoch 37/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9856 - cls_out_loss: 0.0475 - loss: 1.7990 - seg_out_dice: 0.7175 - seg_out_loss: 1.7515\nEpoch 37: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9856 - cls_out_loss: 0.0472 - loss: 1.7987 - seg_out_dice: 0.7178 - seg_out_loss: 1.7515 - val_cls_out_accuracy: 0.6875 - val_cls_out_loss: 1.0002 - val_loss: 2.8040 - val_seg_out_dice: 0.5114 - val_seg_out_loss: 1.8038\nEpoch 38/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9766 - cls_out_loss: 0.0571 - loss: 1.8036 - seg_out_dice: 0.7123 - seg_out_loss: 1.7465\nEpoch 38: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9765 - cls_out_loss: 0.0572 - loss: 1.8039 - seg_out_dice: 0.7124 - seg_out_loss: 1.7467 - val_cls_out_accuracy: 0.6750 - val_cls_out_loss: 1.2829 - val_loss: 3.0889 - val_seg_out_dice: 0.4800 - val_seg_out_loss: 1.8059\nEpoch 39/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9812 - cls_out_loss: 0.0890 - loss: 1.8487 - seg_out_dice: 0.7182 - seg_out_loss: 1.7597\nEpoch 39: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9811 - cls_out_loss: 0.0890 - loss: 1.8486 - seg_out_dice: 0.7176 - seg_out_loss: 1.7596 - val_cls_out_accuracy: 0.7500 - val_cls_out_loss: 1.6047 - val_loss: 3.4079 - val_seg_out_dice: 0.5144 - val_seg_out_loss: 1.8032\nEpoch 40/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9861 - cls_out_loss: 0.0398 - loss: 1.8016 - seg_out_dice: 0.6904 - seg_out_loss: 1.7618\nEpoch 40: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9862 - cls_out_loss: 0.0395 - loss: 1.8012 - seg_out_dice: 0.6905 - seg_out_loss: 1.7616 - val_cls_out_accuracy: 0.6875 - val_cls_out_loss: 1.2880 - val_loss: 3.0914 - val_seg_out_dice: 0.4691 - val_seg_out_loss: 1.8034\nEpoch 41/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9943 - cls_out_loss: 0.0114 - loss: 1.7493 - seg_out_dice: 0.7191 - seg_out_loss: 1.7379\nEpoch 41: val_seg_out_dice did not improve from 0.64021\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9943 - cls_out_loss: 0.0113 - loss: 1.7496 - seg_out_dice: 0.7194 - seg_out_loss: 1.7383 - val_cls_out_accuracy: 0.7250 - val_cls_out_loss: 1.2990 - val_loss: 3.1012 - val_seg_out_dice: 0.5778 - val_seg_out_loss: 1.8021\nEpoch 42/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9996 - cls_out_loss: 0.0033 - loss: 1.7497 - seg_out_dice: 0.7210 - seg_out_loss: 1.7464\nEpoch 42: val_seg_out_dice improved from 0.64021 to 0.64114, saving model to /kaggle/working/best_model.h5\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 520ms/step - cls_out_accuracy: 0.9996 - cls_out_loss: 0.0033 - loss: 1.7499 - seg_out_dice: 0.7216 - seg_out_loss: 1.7466 - val_cls_out_accuracy: 0.7875 - val_cls_out_loss: 0.9932 - val_loss: 2.7965 - val_seg_out_dice: 0.6411 - val_seg_out_loss: 1.8033\nEpoch 43/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0038 - loss: 1.7645 - seg_out_dice: 0.7350 - seg_out_loss: 1.7607\nEpoch 43: val_seg_out_dice did not improve from 0.64114\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0038 - loss: 1.7643 - seg_out_dice: 0.7352 - seg_out_loss: 1.7605 - val_cls_out_accuracy: 0.8250 - val_cls_out_loss: 0.8835 - val_loss: 2.6865 - val_seg_out_dice: 0.6315 - val_seg_out_loss: 1.8029\nEpoch 44/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0015 - loss: 1.7381 - seg_out_dice: 0.7506 - seg_out_loss: 1.7366\nEpoch 44: val_seg_out_dice improved from 0.64114 to 0.64842, saving model to /kaggle/working/best_model.h5\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 519ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0015 - loss: 1.7386 - seg_out_dice: 0.7505 - seg_out_loss: 1.7370 - val_cls_out_accuracy: 0.7500 - val_cls_out_loss: 1.3044 - val_loss: 3.1083 - val_seg_out_dice: 0.6484 - val_seg_out_loss: 1.8039\nEpoch 45/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9995 - cls_out_loss: 0.0027 - loss: 1.7666 - seg_out_dice: 0.7248 - seg_out_loss: 1.7638\nEpoch 45: val_seg_out_dice did not improve from 0.64842\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9995 - cls_out_loss: 0.0028 - loss: 1.7663 - seg_out_dice: 0.7254 - seg_out_loss: 1.7636 - val_cls_out_accuracy: 0.7125 - val_cls_out_loss: 2.0350 - val_loss: 3.8403 - val_seg_out_dice: 0.6375 - val_seg_out_loss: 1.8053\nEpoch 46/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0042 - loss: 1.7513 - seg_out_dice: 0.7423 - seg_out_loss: 1.7471\nEpoch 46: val_seg_out_dice improved from 0.64842 to 0.65127, saving model to /kaggle/working/best_model.h5\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 522ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0042 - loss: 1.7514 - seg_out_dice: 0.7426 - seg_out_loss: 1.7473 - val_cls_out_accuracy: 0.8125 - val_cls_out_loss: 0.9840 - val_loss: 2.7878 - val_seg_out_dice: 0.6513 - val_seg_out_loss: 1.8038\nEpoch 47/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9999 - cls_out_loss: 0.0012 - loss: 1.7474 - seg_out_dice: 0.7723 - seg_out_loss: 1.7462\nEpoch 47: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9999 - cls_out_loss: 0.0012 - loss: 1.7476 - seg_out_dice: 0.7724 - seg_out_loss: 1.7464 - val_cls_out_accuracy: 0.8125 - val_cls_out_loss: 0.9452 - val_loss: 2.7475 - val_seg_out_dice: 0.5986 - val_seg_out_loss: 1.8022\nEpoch 48/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - cls_out_accuracy: 0.9995 - cls_out_loss: 0.0034 - loss: 1.7528 - seg_out_dice: 0.7719 - seg_out_loss: 1.7495\nEpoch 48: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 510ms/step - cls_out_accuracy: 0.9994 - cls_out_loss: 0.0036 - loss: 1.7531 - seg_out_dice: 0.7720 - seg_out_loss: 1.7496 - val_cls_out_accuracy: 0.7125 - val_cls_out_loss: 0.8610 - val_loss: 2.6645 - val_seg_out_dice: 0.5093 - val_seg_out_loss: 1.8036\nEpoch 49/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - cls_out_accuracy: 0.9933 - cls_out_loss: 0.0196 - loss: 1.7698 - seg_out_dice: 0.7280 - seg_out_loss: 1.7502\nEpoch 49: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9932 - cls_out_loss: 0.0199 - loss: 1.7702 - seg_out_dice: 0.7276 - seg_out_loss: 1.7503 - val_cls_out_accuracy: 0.7000 - val_cls_out_loss: 2.5719 - val_loss: 4.3801 - val_seg_out_dice: 0.5935 - val_seg_out_loss: 1.8082\nEpoch 50/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9593 - cls_out_loss: 0.1447 - loss: 1.8898 - seg_out_dice: 0.7080 - seg_out_loss: 1.7451\nEpoch 50: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9596 - cls_out_loss: 0.1435 - loss: 1.8889 - seg_out_dice: 0.7078 - seg_out_loss: 1.7453 - val_cls_out_accuracy: 0.6375 - val_cls_out_loss: 4.2074 - val_loss: 6.0640 - val_seg_out_dice: 0.3572 - val_seg_out_loss: 1.8565\nEpoch 51/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9630 - cls_out_loss: 0.0953 - loss: 1.8305 - seg_out_dice: 0.6933 - seg_out_loss: 1.7351\nEpoch 51: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9634 - cls_out_loss: 0.0944 - loss: 1.8300 - seg_out_dice: 0.6930 - seg_out_loss: 1.7356 - val_cls_out_accuracy: 0.7625 - val_cls_out_loss: 1.7114 - val_loss: 3.5153 - val_seg_out_dice: 0.6171 - val_seg_out_loss: 1.8039\nEpoch 52/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9892 - cls_out_loss: 0.0328 - loss: 1.7820 - seg_out_dice: 0.7270 - seg_out_loss: 1.7492\nEpoch 52: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9893 - cls_out_loss: 0.0326 - loss: 1.7818 - seg_out_dice: 0.7271 - seg_out_loss: 1.7493 - val_cls_out_accuracy: 0.7250 - val_cls_out_loss: 1.8841 - val_loss: 3.6916 - val_seg_out_dice: 0.6305 - val_seg_out_loss: 1.8075\nEpoch 53/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0066 - loss: 1.7672 - seg_out_dice: 0.7459 - seg_out_loss: 1.7606\nEpoch 53: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0066 - loss: 1.7670 - seg_out_dice: 0.7459 - seg_out_loss: 1.7605 - val_cls_out_accuracy: 0.7500 - val_cls_out_loss: 1.8855 - val_loss: 3.6910 - val_seg_out_dice: 0.6347 - val_seg_out_loss: 1.8055\nEpoch 54/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9996 - cls_out_loss: 0.0054 - loss: 1.7676 - seg_out_dice: 0.7578 - seg_out_loss: 1.7622\nEpoch 54: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9996 - cls_out_loss: 0.0055 - loss: 1.7675 - seg_out_dice: 0.7577 - seg_out_loss: 1.7620 - val_cls_out_accuracy: 0.7000 - val_cls_out_loss: 2.5135 - val_loss: 4.3184 - val_seg_out_dice: 0.6430 - val_seg_out_loss: 1.8049\nEpoch 55/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9993 - cls_out_loss: 0.0040 - loss: 1.7500 - seg_out_dice: 0.7474 - seg_out_loss: 1.7460\nEpoch 55: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9993 - cls_out_loss: 0.0040 - loss: 1.7502 - seg_out_dice: 0.7476 - seg_out_loss: 1.7462 - val_cls_out_accuracy: 0.5750 - val_cls_out_loss: 3.9543 - val_loss: 5.7793 - val_seg_out_dice: 0.5172 - val_seg_out_loss: 1.8250\nEpoch 56/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9891 - cls_out_loss: 0.0298 - loss: 1.7781 - seg_out_dice: 0.7856 - seg_out_loss: 1.7483\nEpoch 56: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9891 - cls_out_loss: 0.0297 - loss: 1.7780 - seg_out_dice: 0.7853 - seg_out_loss: 1.7484 - val_cls_out_accuracy: 0.7250 - val_cls_out_loss: 1.7757 - val_loss: 3.5819 - val_seg_out_dice: 0.6123 - val_seg_out_loss: 1.8062\nEpoch 57/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9983 - cls_out_loss: 0.0065 - loss: 1.7711 - seg_out_dice: 0.7499 - seg_out_loss: 1.7646\nEpoch 57: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9983 - cls_out_loss: 0.0066 - loss: 1.7709 - seg_out_dice: 0.7499 - seg_out_loss: 1.7643 - val_cls_out_accuracy: 0.7375 - val_cls_out_loss: 1.2072 - val_loss: 3.0101 - val_seg_out_dice: 0.6212 - val_seg_out_loss: 1.8029\nEpoch 58/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9905 - cls_out_loss: 0.0258 - loss: 1.7712 - seg_out_dice: 0.7584 - seg_out_loss: 1.7455\nEpoch 58: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9905 - cls_out_loss: 0.0259 - loss: 1.7716 - seg_out_dice: 0.7579 - seg_out_loss: 1.7457 - val_cls_out_accuracy: 0.5250 - val_cls_out_loss: 2.1771 - val_loss: 3.9825 - val_seg_out_dice: 0.5266 - val_seg_out_loss: 1.8054\nEpoch 59/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9744 - cls_out_loss: 0.0762 - loss: 1.8303 - seg_out_dice: 0.7253 - seg_out_loss: 1.7541\nEpoch 59: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9743 - cls_out_loss: 0.0764 - loss: 1.8305 - seg_out_dice: 0.7254 - seg_out_loss: 1.7541 - val_cls_out_accuracy: 0.7250 - val_cls_out_loss: 1.8481 - val_loss: 3.6543 - val_seg_out_dice: 0.5662 - val_seg_out_loss: 1.8062\nEpoch 60/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9831 - cls_out_loss: 0.0568 - loss: 1.7957 - seg_out_dice: 0.7243 - seg_out_loss: 1.7389\nEpoch 60: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9833 - cls_out_loss: 0.0562 - loss: 1.7954 - seg_out_dice: 0.7246 - seg_out_loss: 1.7392 - val_cls_out_accuracy: 0.7625 - val_cls_out_loss: 0.8530 - val_loss: 2.6561 - val_seg_out_dice: 0.5792 - val_seg_out_loss: 1.8030\nEpoch 61/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9934 - cls_out_loss: 0.0187 - loss: 1.7641 - seg_out_dice: 0.7644 - seg_out_loss: 1.7454\nEpoch 61: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9934 - cls_out_loss: 0.0187 - loss: 1.7643 - seg_out_dice: 0.7642 - seg_out_loss: 1.7456 - val_cls_out_accuracy: 0.7875 - val_cls_out_loss: 1.0809 - val_loss: 2.8836 - val_seg_out_dice: 0.4631 - val_seg_out_loss: 1.8027\nEpoch 62/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9980 - cls_out_loss: 0.0084 - loss: 1.7696 - seg_out_dice: 0.7518 - seg_out_loss: 1.7612\nEpoch 62: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9979 - cls_out_loss: 0.0085 - loss: 1.7695 - seg_out_dice: 0.7521 - seg_out_loss: 1.7610 - val_cls_out_accuracy: 0.7750 - val_cls_out_loss: 1.5759 - val_loss: 3.3798 - val_seg_out_dice: 0.5651 - val_seg_out_loss: 1.8040\nEpoch 63/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9812 - cls_out_loss: 0.0385 - loss: 1.7965 - seg_out_dice: 0.7592 - seg_out_loss: 1.7580\nEpoch 63: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9814 - cls_out_loss: 0.0382 - loss: 1.7961 - seg_out_dice: 0.7593 - seg_out_loss: 1.7579 - val_cls_out_accuracy: 0.7750 - val_cls_out_loss: 1.4921 - val_loss: 3.2963 - val_seg_out_dice: 0.5596 - val_seg_out_loss: 1.8042\nEpoch 64/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9951 - cls_out_loss: 0.0103 - loss: 1.7685 - seg_out_dice: 0.7805 - seg_out_loss: 1.7581\nEpoch 64: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9951 - cls_out_loss: 0.0103 - loss: 1.7683 - seg_out_dice: 0.7802 - seg_out_loss: 1.7580 - val_cls_out_accuracy: 0.7875 - val_cls_out_loss: 1.1874 - val_loss: 2.9946 - val_seg_out_dice: 0.6032 - val_seg_out_loss: 1.8072\nEpoch 65/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9997 - cls_out_loss: 0.0056 - loss: 1.7593 - seg_out_dice: 0.7680 - seg_out_loss: 1.7537\nEpoch 65: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9997 - cls_out_loss: 0.0057 - loss: 1.7594 - seg_out_dice: 0.7679 - seg_out_loss: 1.7536 - val_cls_out_accuracy: 0.6500 - val_cls_out_loss: 1.9767 - val_loss: 3.7938 - val_seg_out_dice: 0.5538 - val_seg_out_loss: 1.8171\nEpoch 66/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9909 - cls_out_loss: 0.0240 - loss: 1.7868 - seg_out_dice: 0.7626 - seg_out_loss: 1.7628\nEpoch 66: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9909 - cls_out_loss: 0.0243 - loss: 1.7869 - seg_out_dice: 0.7623 - seg_out_loss: 1.7626 - val_cls_out_accuracy: 0.6875 - val_cls_out_loss: 1.2155 - val_loss: 3.0330 - val_seg_out_dice: 0.4111 - val_seg_out_loss: 1.8175\nEpoch 67/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9834 - cls_out_loss: 0.0514 - loss: 1.8160 - seg_out_dice: 0.7577 - seg_out_loss: 1.7646\nEpoch 67: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9833 - cls_out_loss: 0.0518 - loss: 1.8161 - seg_out_dice: 0.7574 - seg_out_loss: 1.7643 - val_cls_out_accuracy: 0.7125 - val_cls_out_loss: 2.3251 - val_loss: 4.1581 - val_seg_out_dice: 0.4232 - val_seg_out_loss: 1.8330\nEpoch 68/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9748 - cls_out_loss: 0.0551 - loss: 1.8019 - seg_out_dice: 0.7327 - seg_out_loss: 1.7468\nEpoch 68: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9750 - cls_out_loss: 0.0548 - loss: 1.8017 - seg_out_dice: 0.7325 - seg_out_loss: 1.7469 - val_cls_out_accuracy: 0.7750 - val_cls_out_loss: 1.0017 - val_loss: 2.8048 - val_seg_out_dice: 0.6025 - val_seg_out_loss: 1.8031\nEpoch 69/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9966 - cls_out_loss: 0.0107 - loss: 1.7585 - seg_out_dice: 0.7706 - seg_out_loss: 1.7478\nEpoch 69: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9966 - cls_out_loss: 0.0106 - loss: 1.7585 - seg_out_dice: 0.7707 - seg_out_loss: 1.7479 - val_cls_out_accuracy: 0.7875 - val_cls_out_loss: 1.5334 - val_loss: 3.3369 - val_seg_out_dice: 0.6277 - val_seg_out_loss: 1.8035\nEpoch 70/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0027 - loss: 1.7628 - seg_out_dice: 0.7810 - seg_out_loss: 1.7601\nEpoch 70: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0028 - loss: 1.7627 - seg_out_dice: 0.7811 - seg_out_loss: 1.7599 - val_cls_out_accuracy: 0.7750 - val_cls_out_loss: 1.2698 - val_loss: 3.0722 - val_seg_out_dice: 0.5535 - val_seg_out_loss: 1.8024\nEpoch 71/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0028 - loss: 1.7371 - seg_out_dice: 0.7860 - seg_out_loss: 1.7343\nEpoch 71: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0029 - loss: 1.7376 - seg_out_dice: 0.7862 - seg_out_loss: 1.7347 - val_cls_out_accuracy: 0.7500 - val_cls_out_loss: 1.2121 - val_loss: 3.0157 - val_seg_out_dice: 0.6462 - val_seg_out_loss: 1.8036\nEpoch 72/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0049 - loss: 1.7719 - seg_out_dice: 0.7930 - seg_out_loss: 1.7670\nEpoch 72: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0048 - loss: 1.7715 - seg_out_dice: 0.7930 - seg_out_loss: 1.7667 - val_cls_out_accuracy: 0.6750 - val_cls_out_loss: 1.8561 - val_loss: 3.6617 - val_seg_out_dice: 0.6366 - val_seg_out_loss: 1.8056\nEpoch 73/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 8.1038e-04 - loss: 1.7503 - seg_out_dice: 0.7767 - seg_out_loss: 1.7495\nEpoch 73: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 8.1555e-04 - loss: 1.7503 - seg_out_dice: 0.7771 - seg_out_loss: 1.7495 - val_cls_out_accuracy: 0.7000 - val_cls_out_loss: 1.7263 - val_loss: 3.5296 - val_seg_out_dice: 0.6469 - val_seg_out_loss: 1.8033\nEpoch 74/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0017 - loss: 1.7491 - seg_out_dice: 0.8107 - seg_out_loss: 1.7474\nEpoch 74: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0017 - loss: 1.7492 - seg_out_dice: 0.8106 - seg_out_loss: 1.7475 - val_cls_out_accuracy: 0.7625 - val_cls_out_loss: 1.3597 - val_loss: 3.1647 - val_seg_out_dice: 0.6389 - val_seg_out_loss: 1.8050\nEpoch 75/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9985 - cls_out_loss: 0.0028 - loss: 1.7546 - seg_out_dice: 0.8024 - seg_out_loss: 1.7518\nEpoch 75: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9984 - cls_out_loss: 0.0029 - loss: 1.7547 - seg_out_dice: 0.8023 - seg_out_loss: 1.7518 - val_cls_out_accuracy: 0.6875 - val_cls_out_loss: 2.9176 - val_loss: 4.7278 - val_seg_out_dice: 0.6067 - val_seg_out_loss: 1.8102\nEpoch 76/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9856 - cls_out_loss: 0.0453 - loss: 1.7993 - seg_out_dice: 0.7859 - seg_out_loss: 1.7540\nEpoch 76: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9854 - cls_out_loss: 0.0457 - loss: 1.7997 - seg_out_dice: 0.7853 - seg_out_loss: 1.7540 - val_cls_out_accuracy: 0.7375 - val_cls_out_loss: 1.5218 - val_loss: 3.3303 - val_seg_out_dice: 0.5790 - val_seg_out_loss: 1.8085\nEpoch 77/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - cls_out_accuracy: 0.9794 - cls_out_loss: 0.0471 - loss: 1.8155 - seg_out_dice: 0.7352 - seg_out_loss: 1.7684\nEpoch 77: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9795 - cls_out_loss: 0.0469 - loss: 1.8149 - seg_out_dice: 0.7349 - seg_out_loss: 1.7681 - val_cls_out_accuracy: 0.7000 - val_cls_out_loss: 1.6595 - val_loss: 3.4642 - val_seg_out_dice: 0.5991 - val_seg_out_loss: 1.8046\nEpoch 78/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9883 - cls_out_loss: 0.0538 - loss: 1.8210 - seg_out_dice: 0.7611 - seg_out_loss: 1.7673\nEpoch 78: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9884 - cls_out_loss: 0.0532 - loss: 1.8202 - seg_out_dice: 0.7609 - seg_out_loss: 1.7669 - val_cls_out_accuracy: 0.7250 - val_cls_out_loss: 1.9999 - val_loss: 3.8051 - val_seg_out_dice: 0.6200 - val_seg_out_loss: 1.8052\nEpoch 79/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9971 - cls_out_loss: 0.0121 - loss: 1.7702 - seg_out_dice: 0.7648 - seg_out_loss: 1.7581\nEpoch 79: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9971 - cls_out_loss: 0.0121 - loss: 1.7700 - seg_out_dice: 0.7648 - seg_out_loss: 1.7579 - val_cls_out_accuracy: 0.7625 - val_cls_out_loss: 1.2596 - val_loss: 3.0626 - val_seg_out_dice: 0.6343 - val_seg_out_loss: 1.8031\nEpoch 80/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9995 - cls_out_loss: 0.0027 - loss: 1.7405 - seg_out_dice: 0.7774 - seg_out_loss: 1.7378\nEpoch 80: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9995 - cls_out_loss: 0.0028 - loss: 1.7409 - seg_out_dice: 0.7775 - seg_out_loss: 1.7381 - val_cls_out_accuracy: 0.6750 - val_cls_out_loss: 2.1703 - val_loss: 3.9728 - val_seg_out_dice: 0.6149 - val_seg_out_loss: 1.8026\nEpoch 81/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9960 - cls_out_loss: 0.0101 - loss: 1.7618 - seg_out_dice: 0.7897 - seg_out_loss: 1.7517\nEpoch 81: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9960 - cls_out_loss: 0.0102 - loss: 1.7619 - seg_out_dice: 0.7895 - seg_out_loss: 1.7517 - val_cls_out_accuracy: 0.7625 - val_cls_out_loss: 1.3289 - val_loss: 3.1382 - val_seg_out_dice: 0.5938 - val_seg_out_loss: 1.8093\nEpoch 82/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9993 - cls_out_loss: 0.0061 - loss: 1.7462 - seg_out_dice: 0.7823 - seg_out_loss: 1.7401\nEpoch 82: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9993 - cls_out_loss: 0.0061 - loss: 1.7465 - seg_out_dice: 0.7826 - seg_out_loss: 1.7404 - val_cls_out_accuracy: 0.7625 - val_cls_out_loss: 1.3388 - val_loss: 3.1449 - val_seg_out_dice: 0.6361 - val_seg_out_loss: 1.8062\nEpoch 83/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9997 - cls_out_loss: 0.0036 - loss: 1.7667 - seg_out_dice: 0.7893 - seg_out_loss: 1.7631\nEpoch 83: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9997 - cls_out_loss: 0.0036 - loss: 1.7664 - seg_out_dice: 0.7894 - seg_out_loss: 1.7628 - val_cls_out_accuracy: 0.8125 - val_cls_out_loss: 1.1418 - val_loss: 2.9486 - val_seg_out_dice: 0.6301 - val_seg_out_loss: 1.8068\nEpoch 84/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0025 - loss: 1.7559 - seg_out_dice: 0.8151 - seg_out_loss: 1.7533\nEpoch 84: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0025 - loss: 1.7558 - seg_out_dice: 0.8151 - seg_out_loss: 1.7533 - val_cls_out_accuracy: 0.8250 - val_cls_out_loss: 1.2011 - val_loss: 3.0060 - val_seg_out_dice: 0.6358 - val_seg_out_loss: 1.8048\nEpoch 85/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9971 - cls_out_loss: 0.0075 - loss: 1.7590 - seg_out_dice: 0.8200 - seg_out_loss: 1.7515\nEpoch 85: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9972 - cls_out_loss: 0.0074 - loss: 1.7590 - seg_out_dice: 0.8196 - seg_out_loss: 1.7515 - val_cls_out_accuracy: 0.7250 - val_cls_out_loss: 1.8499 - val_loss: 3.6551 - val_seg_out_dice: 0.6310 - val_seg_out_loss: 1.8052\nEpoch 86/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9806 - cls_out_loss: 0.0529 - loss: 1.7986 - seg_out_dice: 0.7781 - seg_out_loss: 1.7457\nEpoch 86: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9808 - cls_out_loss: 0.0524 - loss: 1.7982 - seg_out_dice: 0.7781 - seg_out_loss: 1.7458 - val_cls_out_accuracy: 0.6125 - val_cls_out_loss: 3.1035 - val_loss: 4.9207 - val_seg_out_dice: 0.5605 - val_seg_out_loss: 1.8171\nEpoch 87/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9988 - cls_out_loss: 0.0060 - loss: 1.7546 - seg_out_dice: 0.8117 - seg_out_loss: 1.7487\nEpoch 87: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9988 - cls_out_loss: 0.0061 - loss: 1.7548 - seg_out_dice: 0.8114 - seg_out_loss: 1.7487 - val_cls_out_accuracy: 0.6375 - val_cls_out_loss: 2.4114 - val_loss: 4.2179 - val_seg_out_dice: 0.5841 - val_seg_out_loss: 1.8065\nEpoch 88/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9852 - cls_out_loss: 0.0367 - loss: 1.7890 - seg_out_dice: 0.8031 - seg_out_loss: 1.7523\nEpoch 88: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9850 - cls_out_loss: 0.0373 - loss: 1.7896 - seg_out_dice: 0.8024 - seg_out_loss: 1.7523 - val_cls_out_accuracy: 0.7750 - val_cls_out_loss: 2.7600 - val_loss: 4.5819 - val_seg_out_dice: 0.5107 - val_seg_out_loss: 1.8218\nEpoch 89/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9880 - cls_out_loss: 0.0539 - loss: 1.8111 - seg_out_dice: 0.7412 - seg_out_loss: 1.7572\nEpoch 89: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9877 - cls_out_loss: 0.0553 - loss: 1.8124 - seg_out_dice: 0.7412 - seg_out_loss: 1.7571 - val_cls_out_accuracy: 0.5625 - val_cls_out_loss: 1.9666 - val_loss: 3.7810 - val_seg_out_dice: 0.5220 - val_seg_out_loss: 1.8144\nEpoch 90/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9748 - cls_out_loss: 0.0776 - loss: 1.8310 - seg_out_dice: 0.7424 - seg_out_loss: 1.7534\nEpoch 90: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9749 - cls_out_loss: 0.0773 - loss: 1.8307 - seg_out_dice: 0.7421 - seg_out_loss: 1.7534 - val_cls_out_accuracy: 0.7125 - val_cls_out_loss: 1.1947 - val_loss: 3.0030 - val_seg_out_dice: 0.5655 - val_seg_out_loss: 1.8084\nEpoch 91/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9984 - cls_out_loss: 0.0213 - loss: 1.7849 - seg_out_dice: 0.7772 - seg_out_loss: 1.7636\nEpoch 91: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9983 - cls_out_loss: 0.0214 - loss: 1.7847 - seg_out_dice: 0.7773 - seg_out_loss: 1.7633 - val_cls_out_accuracy: 0.6000 - val_cls_out_loss: 4.0353 - val_loss: 5.8641 - val_seg_out_dice: 0.4655 - val_seg_out_loss: 1.8288\nEpoch 92/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0057 - loss: 1.7462 - seg_out_dice: 0.7753 - seg_out_loss: 1.7405\nEpoch 92: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0057 - loss: 1.7465 - seg_out_dice: 0.7756 - seg_out_loss: 1.7408 - val_cls_out_accuracy: 0.7250 - val_cls_out_loss: 2.1148 - val_loss: 3.9290 - val_seg_out_dice: 0.5703 - val_seg_out_loss: 1.8142\nEpoch 93/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0025 - loss: 1.7650 - seg_out_dice: 0.7810 - seg_out_loss: 1.7626\nEpoch 93: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0025 - loss: 1.7648 - seg_out_dice: 0.7816 - seg_out_loss: 1.7623 - val_cls_out_accuracy: 0.7250 - val_cls_out_loss: 1.3346 - val_loss: 3.1400 - val_seg_out_dice: 0.6494 - val_seg_out_loss: 1.8054\nEpoch 94/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0018 - loss: 1.7500 - seg_out_dice: 0.8078 - seg_out_loss: 1.7482\nEpoch 94: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0018 - loss: 1.7501 - seg_out_dice: 0.8079 - seg_out_loss: 1.7483 - val_cls_out_accuracy: 0.7250 - val_cls_out_loss: 1.3901 - val_loss: 3.1945 - val_seg_out_dice: 0.6431 - val_seg_out_loss: 1.8045\nEpoch 95/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9991 - cls_out_loss: 0.0019 - loss: 1.7455 - seg_out_dice: 0.8135 - seg_out_loss: 1.7437\nEpoch 95: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9990 - cls_out_loss: 0.0020 - loss: 1.7458 - seg_out_dice: 0.8133 - seg_out_loss: 1.7438 - val_cls_out_accuracy: 0.7125 - val_cls_out_loss: 1.2884 - val_loss: 3.0929 - val_seg_out_dice: 0.6336 - val_seg_out_loss: 1.8045\nEpoch 96/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0027 - loss: 1.7673 - seg_out_dice: 0.8149 - seg_out_loss: 1.7646\nEpoch 96: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0027 - loss: 1.7669 - seg_out_dice: 0.8150 - seg_out_loss: 1.7642 - val_cls_out_accuracy: 0.6875 - val_cls_out_loss: 1.2548 - val_loss: 3.0609 - val_seg_out_dice: 0.6430 - val_seg_out_loss: 1.8061\nEpoch 97/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0012 - loss: 1.7543 - seg_out_dice: 0.8280 - seg_out_loss: 1.7531\nEpoch 97: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0013 - loss: 1.7543 - seg_out_dice: 0.8281 - seg_out_loss: 1.7530 - val_cls_out_accuracy: 0.7625 - val_cls_out_loss: 1.0212 - val_loss: 2.8254 - val_seg_out_dice: 0.6296 - val_seg_out_loss: 1.8041\nEpoch 98/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 5.2541e-04 - loss: 1.7526 - seg_out_dice: 0.8337 - seg_out_loss: 1.7521\nEpoch 98: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 5.3151e-04 - loss: 1.7526 - seg_out_dice: 0.8334 - seg_out_loss: 1.7521 - val_cls_out_accuracy: 0.7625 - val_cls_out_loss: 0.9796 - val_loss: 2.7828 - val_seg_out_dice: 0.6224 - val_seg_out_loss: 1.8032\nEpoch 99/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9950 - cls_out_loss: 0.0124 - loss: 1.7683 - seg_out_dice: 0.8214 - seg_out_loss: 1.7559\nEpoch 99: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9950 - cls_out_loss: 0.0124 - loss: 1.7683 - seg_out_dice: 0.8214 - seg_out_loss: 1.7558 - val_cls_out_accuracy: 0.6250 - val_cls_out_loss: 2.7716 - val_loss: 4.5927 - val_seg_out_dice: 0.5214 - val_seg_out_loss: 1.8210\nEpoch 100/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9991 - cls_out_loss: 0.0038 - loss: 1.7489 - seg_out_dice: 0.7968 - seg_out_loss: 1.7450\nEpoch 100: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9990 - cls_out_loss: 0.0041 - loss: 1.7493 - seg_out_dice: 0.7971 - seg_out_loss: 1.7452 - val_cls_out_accuracy: 0.7750 - val_cls_out_loss: 1.4894 - val_loss: 3.2972 - val_seg_out_dice: 0.5867 - val_seg_out_loss: 1.8079\nEpoch 101/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9980 - cls_out_loss: 0.0129 - loss: 1.7486 - seg_out_dice: 0.8078 - seg_out_loss: 1.7357\nEpoch 101: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9980 - cls_out_loss: 0.0129 - loss: 1.7489 - seg_out_dice: 0.8076 - seg_out_loss: 1.7361 - val_cls_out_accuracy: 0.7625 - val_cls_out_loss: 1.7771 - val_loss: 3.5839 - val_seg_out_dice: 0.6201 - val_seg_out_loss: 1.8068\nEpoch 102/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9943 - cls_out_loss: 0.0087 - loss: 1.7648 - seg_out_dice: 0.8272 - seg_out_loss: 1.7562\nEpoch 102: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9944 - cls_out_loss: 0.0086 - loss: 1.7647 - seg_out_dice: 0.8270 - seg_out_loss: 1.7560 - val_cls_out_accuracy: 0.7000 - val_cls_out_loss: 1.9022 - val_loss: 3.7090 - val_seg_out_dice: 0.6380 - val_seg_out_loss: 1.8068\nEpoch 103/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9971 - cls_out_loss: 0.0063 - loss: 1.7592 - seg_out_dice: 0.8154 - seg_out_loss: 1.7529\nEpoch 103: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9972 - cls_out_loss: 0.0062 - loss: 1.7591 - seg_out_dice: 0.8154 - seg_out_loss: 1.7529 - val_cls_out_accuracy: 0.7250 - val_cls_out_loss: 1.9047 - val_loss: 3.7098 - val_seg_out_dice: 0.6123 - val_seg_out_loss: 1.8051\nEpoch 104/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0017 - loss: 1.7698 - seg_out_dice: 0.8017 - seg_out_loss: 1.7681\nEpoch 104: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0017 - loss: 1.7694 - seg_out_dice: 0.8019 - seg_out_loss: 1.7677 - val_cls_out_accuracy: 0.7625 - val_cls_out_loss: 1.4921 - val_loss: 3.2968 - val_seg_out_dice: 0.6461 - val_seg_out_loss: 1.8048\nEpoch 105/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0012 - loss: 1.7312 - seg_out_dice: 0.8229 - seg_out_loss: 1.7300\nEpoch 105: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0012 - loss: 1.7317 - seg_out_dice: 0.8228 - seg_out_loss: 1.7305 - val_cls_out_accuracy: 0.7875 - val_cls_out_loss: 1.3325 - val_loss: 3.1350 - val_seg_out_dice: 0.6172 - val_seg_out_loss: 1.8025\nEpoch 106/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 6.7066e-04 - loss: 1.7544 - seg_out_dice: 0.8366 - seg_out_loss: 1.7537\nEpoch 106: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 6.8350e-04 - loss: 1.7543 - seg_out_dice: 0.8365 - seg_out_loss: 1.7537 - val_cls_out_accuracy: 0.8375 - val_cls_out_loss: 1.1117 - val_loss: 2.9162 - val_seg_out_dice: 0.6424 - val_seg_out_loss: 1.8045\nEpoch 107/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9929 - cls_out_loss: 0.0143 - loss: 1.7579 - seg_out_dice: 0.8307 - seg_out_loss: 1.7436\nEpoch 107: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9929 - cls_out_loss: 0.0144 - loss: 1.7582 - seg_out_dice: 0.8304 - seg_out_loss: 1.7438 - val_cls_out_accuracy: 0.4750 - val_cls_out_loss: 4.9411 - val_loss: 6.7483 - val_seg_out_dice: 0.6013 - val_seg_out_loss: 1.8073\nEpoch 108/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9916 - cls_out_loss: 0.0170 - loss: 1.7771 - seg_out_dice: 0.7718 - seg_out_loss: 1.7601\nEpoch 108: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9917 - cls_out_loss: 0.0169 - loss: 1.7768 - seg_out_dice: 0.7720 - seg_out_loss: 1.7599 - val_cls_out_accuracy: 0.6875 - val_cls_out_loss: 3.6966 - val_loss: 5.5108 - val_seg_out_dice: 0.5181 - val_seg_out_loss: 1.8142\nEpoch 109/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9892 - cls_out_loss: 0.0424 - loss: 1.7996 - seg_out_dice: 0.8003 - seg_out_loss: 1.7573\nEpoch 109: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9891 - cls_out_loss: 0.0425 - loss: 1.7997 - seg_out_dice: 0.8001 - seg_out_loss: 1.7571 - val_cls_out_accuracy: 0.6125 - val_cls_out_loss: 5.0517 - val_loss: 6.8635 - val_seg_out_dice: 0.4634 - val_seg_out_loss: 1.8118\nEpoch 110/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9531 - cls_out_loss: 0.1921 - loss: 1.9479 - seg_out_dice: 0.7770 - seg_out_loss: 1.7558\nEpoch 110: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9527 - cls_out_loss: 0.1937 - loss: 1.9494 - seg_out_dice: 0.7761 - seg_out_loss: 1.7557 - val_cls_out_accuracy: 0.5500 - val_cls_out_loss: 4.1145 - val_loss: 5.9180 - val_seg_out_dice: 0.5142 - val_seg_out_loss: 1.8034\nEpoch 111/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9807 - cls_out_loss: 0.0692 - loss: 1.8301 - seg_out_dice: 0.6968 - seg_out_loss: 1.7609\nEpoch 111: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9808 - cls_out_loss: 0.0688 - loss: 1.8296 - seg_out_dice: 0.6967 - seg_out_loss: 1.7608 - val_cls_out_accuracy: 0.6000 - val_cls_out_loss: 4.0970 - val_loss: 5.9144 - val_seg_out_dice: 0.4889 - val_seg_out_loss: 1.8174\nEpoch 112/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - cls_out_accuracy: 0.9978 - cls_out_loss: 0.0182 - loss: 1.7656 - seg_out_dice: 0.7629 - seg_out_loss: 1.7475\nEpoch 112: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 504ms/step - cls_out_accuracy: 0.9978 - cls_out_loss: 0.0182 - loss: 1.7658 - seg_out_dice: 0.7633 - seg_out_loss: 1.7476 - val_cls_out_accuracy: 0.7500 - val_cls_out_loss: 1.5358 - val_loss: 3.3428 - val_seg_out_dice: 0.6031 - val_seg_out_loss: 1.8070\nEpoch 113/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9998 - cls_out_loss: 0.0069 - loss: 1.7587 - seg_out_dice: 0.7931 - seg_out_loss: 1.7518\nEpoch 113: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9998 - cls_out_loss: 0.0069 - loss: 1.7587 - seg_out_dice: 0.7934 - seg_out_loss: 1.7518 - val_cls_out_accuracy: 0.7875 - val_cls_out_loss: 0.8359 - val_loss: 2.6405 - val_seg_out_dice: 0.6227 - val_seg_out_loss: 1.8046\nEpoch 114/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0012 - loss: 1.7461 - seg_out_dice: 0.8226 - seg_out_loss: 1.7450 \nEpoch 114: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0012 - loss: 1.7463 - seg_out_dice: 0.8225 - seg_out_loss: 1.7451 - val_cls_out_accuracy: 0.7125 - val_cls_out_loss: 1.4571 - val_loss: 3.2620 - val_seg_out_dice: 0.6006 - val_seg_out_loss: 1.8049\nEpoch 115/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0025 - loss: 1.7571 - seg_out_dice: 0.8165 - seg_out_loss: 1.7546\nEpoch 115: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0025 - loss: 1.7570 - seg_out_dice: 0.8167 - seg_out_loss: 1.7545 - val_cls_out_accuracy: 0.7500 - val_cls_out_loss: 1.2626 - val_loss: 3.0678 - val_seg_out_dice: 0.6478 - val_seg_out_loss: 1.8051\nEpoch 116/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0017 - loss: 1.7591 - seg_out_dice: 0.8188 - seg_out_loss: 1.7574\nEpoch 116: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0017 - loss: 1.7589 - seg_out_dice: 0.8190 - seg_out_loss: 1.7572 - val_cls_out_accuracy: 0.7375 - val_cls_out_loss: 1.0445 - val_loss: 2.8474 - val_seg_out_dice: 0.6187 - val_seg_out_loss: 1.8028\nEpoch 117/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 8.8893e-04 - loss: 1.7514 - seg_out_dice: 0.8460 - seg_out_loss: 1.7505\nEpoch 117: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 8.9753e-04 - loss: 1.7514 - seg_out_dice: 0.8457 - seg_out_loss: 1.7505 - val_cls_out_accuracy: 0.7750 - val_cls_out_loss: 0.9005 - val_loss: 2.7049 - val_seg_out_dice: 0.6334 - val_seg_out_loss: 1.8044\nEpoch 118/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 8.3777e-04 - loss: 1.7582 - seg_out_dice: 0.8262 - seg_out_loss: 1.7574\nEpoch 118: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 8.4438e-04 - loss: 1.7581 - seg_out_dice: 0.8263 - seg_out_loss: 1.7572 - val_cls_out_accuracy: 0.7875 - val_cls_out_loss: 0.8751 - val_loss: 2.6802 - val_seg_out_dice: 0.6452 - val_seg_out_loss: 1.8051\nEpoch 119/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0011 - loss: 1.7549 - seg_out_dice: 0.8268 - seg_out_loss: 1.7538\nEpoch 119: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0011 - loss: 1.7548 - seg_out_dice: 0.8271 - seg_out_loss: 1.7537 - val_cls_out_accuracy: 0.7625 - val_cls_out_loss: 0.9508 - val_loss: 2.7561 - val_seg_out_dice: 0.6366 - val_seg_out_loss: 1.8053\nEpoch 120/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9933 - cls_out_loss: 0.0079 - loss: 1.7605 - seg_out_dice: 0.8395 - seg_out_loss: 1.7526\nEpoch 120: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9934 - cls_out_loss: 0.0078 - loss: 1.7603 - seg_out_dice: 0.8396 - seg_out_loss: 1.7525 - val_cls_out_accuracy: 0.7875 - val_cls_out_loss: 1.0988 - val_loss: 2.9029 - val_seg_out_dice: 0.6060 - val_seg_out_loss: 1.8041\nEpoch 121/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0013 - loss: 1.7487 - seg_out_dice: 0.8557 - seg_out_loss: 1.7473\nEpoch 121: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0013 - loss: 1.7487 - seg_out_dice: 0.8554 - seg_out_loss: 1.7474 - val_cls_out_accuracy: 0.7875 - val_cls_out_loss: 1.0624 - val_loss: 2.8691 - val_seg_out_dice: 0.6251 - val_seg_out_loss: 1.8067\nEpoch 122/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9999 - cls_out_loss: 0.0016 - loss: 1.7455 - seg_out_dice: 0.8291 - seg_out_loss: 1.7438\nEpoch 122: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9999 - cls_out_loss: 0.0017 - loss: 1.7457 - seg_out_dice: 0.8292 - seg_out_loss: 1.7440 - val_cls_out_accuracy: 0.7625 - val_cls_out_loss: 1.1315 - val_loss: 2.9387 - val_seg_out_dice: 0.6325 - val_seg_out_loss: 1.8072\nEpoch 123/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9896 - cls_out_loss: 0.0312 - loss: 1.7631 - seg_out_dice: 0.8441 - seg_out_loss: 1.7319\nEpoch 123: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9895 - cls_out_loss: 0.0317 - loss: 1.7641 - seg_out_dice: 0.8437 - seg_out_loss: 1.7324 - val_cls_out_accuracy: 0.6875 - val_cls_out_loss: 1.5901 - val_loss: 3.3998 - val_seg_out_dice: 0.5618 - val_seg_out_loss: 1.8097\nEpoch 124/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9844 - cls_out_loss: 0.0499 - loss: 1.8018 - seg_out_dice: 0.7648 - seg_out_loss: 1.7519\nEpoch 124: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9845 - cls_out_loss: 0.0496 - loss: 1.8015 - seg_out_dice: 0.7653 - seg_out_loss: 1.7519 - val_cls_out_accuracy: 0.6125 - val_cls_out_loss: 1.4967 - val_loss: 3.3019 - val_seg_out_dice: 0.4823 - val_seg_out_loss: 1.8053\nEpoch 125/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9952 - cls_out_loss: 0.0182 - loss: 1.7614 - seg_out_dice: 0.7985 - seg_out_loss: 1.7433\nEpoch 125: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9952 - cls_out_loss: 0.0182 - loss: 1.7617 - seg_out_dice: 0.7988 - seg_out_loss: 1.7434 - val_cls_out_accuracy: 0.5625 - val_cls_out_loss: 2.7277 - val_loss: 4.5319 - val_seg_out_dice: 0.6231 - val_seg_out_loss: 1.8041\nEpoch 126/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9927 - cls_out_loss: 0.0116 - loss: 1.7438 - seg_out_dice: 0.8250 - seg_out_loss: 1.7322\nEpoch 126: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9927 - cls_out_loss: 0.0117 - loss: 1.7444 - seg_out_dice: 0.8246 - seg_out_loss: 1.7327 - val_cls_out_accuracy: 0.7375 - val_cls_out_loss: 1.0851 - val_loss: 2.8890 - val_seg_out_dice: 0.5746 - val_seg_out_loss: 1.8039\nEpoch 127/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9997 - cls_out_loss: 0.0121 - loss: 1.7630 - seg_out_dice: 0.8234 - seg_out_loss: 1.7509\nEpoch 127: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9997 - cls_out_loss: 0.0121 - loss: 1.7630 - seg_out_dice: 0.8234 - seg_out_loss: 1.7509 - val_cls_out_accuracy: 0.7750 - val_cls_out_loss: 1.7659 - val_loss: 3.5705 - val_seg_out_dice: 0.6252 - val_seg_out_loss: 1.8046\nEpoch 128/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0030 - loss: 1.7505 - seg_out_dice: 0.8315 - seg_out_loss: 1.7475\nEpoch 128: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0030 - loss: 1.7506 - seg_out_dice: 0.8316 - seg_out_loss: 1.7476 - val_cls_out_accuracy: 0.8125 - val_cls_out_loss: 1.2169 - val_loss: 3.0237 - val_seg_out_dice: 0.6336 - val_seg_out_loss: 1.8068\nEpoch 129/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0011 - loss: 1.7454 - seg_out_dice: 0.8212 - seg_out_loss: 1.7443\nEpoch 129: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0011 - loss: 1.7455 - seg_out_dice: 0.8218 - seg_out_loss: 1.7445 - val_cls_out_accuracy: 0.8000 - val_cls_out_loss: 1.0522 - val_loss: 2.8565 - val_seg_out_dice: 0.6420 - val_seg_out_loss: 1.8042\nEpoch 130/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 5.3411e-04 - loss: 1.7453 - seg_out_dice: 0.8569 - seg_out_loss: 1.7448\nEpoch 130: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 5.4516e-04 - loss: 1.7454 - seg_out_dice: 0.8565 - seg_out_loss: 1.7449 - val_cls_out_accuracy: 0.8125 - val_cls_out_loss: 1.0117 - val_loss: 2.8156 - val_seg_out_dice: 0.6328 - val_seg_out_loss: 1.8039\nEpoch 131/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 3.9512e-04 - loss: 1.7527 - seg_out_dice: 0.8561 - seg_out_loss: 1.7523\nEpoch 131: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 3.9403e-04 - loss: 1.7526 - seg_out_dice: 0.8562 - seg_out_loss: 1.7523 - val_cls_out_accuracy: 0.8000 - val_cls_out_loss: 0.9744 - val_loss: 2.7776 - val_seg_out_dice: 0.6256 - val_seg_out_loss: 1.8032\nEpoch 132/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9983 - cls_out_loss: 0.0035 - loss: 1.7587 - seg_out_dice: 0.8637 - seg_out_loss: 1.7552\nEpoch 132: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9982 - cls_out_loss: 0.0037 - loss: 1.7587 - seg_out_dice: 0.8634 - seg_out_loss: 1.7550 - val_cls_out_accuracy: 0.6000 - val_cls_out_loss: 1.8496 - val_loss: 3.6531 - val_seg_out_dice: 0.5526 - val_seg_out_loss: 1.8036\nEpoch 133/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9952 - cls_out_loss: 0.0251 - loss: 1.7813 - seg_out_dice: 0.8112 - seg_out_loss: 1.7563\nEpoch 133: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9952 - cls_out_loss: 0.0251 - loss: 1.7813 - seg_out_dice: 0.8111 - seg_out_loss: 1.7562 - val_cls_out_accuracy: 0.8125 - val_cls_out_loss: 1.1827 - val_loss: 2.9895 - val_seg_out_dice: 0.6047 - val_seg_out_loss: 1.8068\nEpoch 134/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9938 - cls_out_loss: 0.0180 - loss: 1.7646 - seg_out_dice: 0.8224 - seg_out_loss: 1.7466\nEpoch 134: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9937 - cls_out_loss: 0.0185 - loss: 1.7652 - seg_out_dice: 0.8223 - seg_out_loss: 1.7467 - val_cls_out_accuracy: 0.7125 - val_cls_out_loss: 5.3359 - val_loss: 7.1422 - val_seg_out_dice: 0.6051 - val_seg_out_loss: 1.8063\nEpoch 135/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9932 - cls_out_loss: 0.0137 - loss: 1.7619 - seg_out_dice: 0.8017 - seg_out_loss: 1.7482\nEpoch 135: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9930 - cls_out_loss: 0.0139 - loss: 1.7622 - seg_out_dice: 0.8018 - seg_out_loss: 1.7483 - val_cls_out_accuracy: 0.7375 - val_cls_out_loss: 1.4959 - val_loss: 3.3030 - val_seg_out_dice: 0.5797 - val_seg_out_loss: 1.8071\nEpoch 136/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0072 - loss: 1.7572 - seg_out_dice: 0.8271 - seg_out_loss: 1.7500\nEpoch 136: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 0.0072 - loss: 1.7571 - seg_out_dice: 0.8272 - seg_out_loss: 1.7500 - val_cls_out_accuracy: 0.7750 - val_cls_out_loss: 1.4279 - val_loss: 3.2320 - val_seg_out_dice: 0.6186 - val_seg_out_loss: 1.8041\nEpoch 137/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9976 - cls_out_loss: 0.0110 - loss: 1.7572 - seg_out_dice: 0.8384 - seg_out_loss: 1.7462\nEpoch 137: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 506ms/step - cls_out_accuracy: 0.9975 - cls_out_loss: 0.0111 - loss: 1.7574 - seg_out_dice: 0.8385 - seg_out_loss: 1.7463 - val_cls_out_accuracy: 0.7250 - val_cls_out_loss: 1.3518 - val_loss: 3.1544 - val_seg_out_dice: 0.6243 - val_seg_out_loss: 1.8025\nEpoch 138/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - cls_out_accuracy: 0.9821 - cls_out_loss: 0.0515 - loss: 1.8087 - seg_out_dice: 0.8105 - seg_out_loss: 1.7573\nEpoch 138: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 507ms/step - cls_out_accuracy: 0.9820 - cls_out_loss: 0.0520 - loss: 1.8091 - seg_out_dice: 0.8103 - seg_out_loss: 1.7572 - val_cls_out_accuracy: 0.6375 - val_cls_out_loss: 6.7443 - val_loss: 8.5821 - val_seg_out_dice: 0.3639 - val_seg_out_loss: 1.8378\nEpoch 139/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - cls_out_accuracy: 0.9862 - cls_out_loss: 0.0490 - loss: 1.7939 - seg_out_dice: 0.7572 - seg_out_loss: 1.7449\nEpoch 139: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9861 - cls_out_loss: 0.0492 - loss: 1.7943 - seg_out_dice: 0.7572 - seg_out_loss: 1.7451 - val_cls_out_accuracy: 0.7625 - val_cls_out_loss: 3.0318 - val_loss: 4.8433 - val_seg_out_dice: 0.5371 - val_seg_out_loss: 1.8115\nEpoch 140/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - cls_out_accuracy: 0.9884 - cls_out_loss: 0.0301 - loss: 1.7790 - seg_out_dice: 0.8020 - seg_out_loss: 1.7490\nEpoch 140: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - cls_out_accuracy: 0.9885 - cls_out_loss: 0.0298 - loss: 1.7788 - seg_out_dice: 0.8021 - seg_out_loss: 1.7490 - val_cls_out_accuracy: 0.5875 - val_cls_out_loss: 1.8314 - val_loss: 3.6361 - val_seg_out_dice: 0.6015 - val_seg_out_loss: 1.8047\nEpoch 141/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9971 - cls_out_loss: 0.0078 - loss: 1.7610 - seg_out_dice: 0.8389 - seg_out_loss: 1.7532\nEpoch 141: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9971 - cls_out_loss: 0.0078 - loss: 1.7610 - seg_out_dice: 0.8387 - seg_out_loss: 1.7532 - val_cls_out_accuracy: 0.7125 - val_cls_out_loss: 1.4729 - val_loss: 3.2763 - val_seg_out_dice: 0.6226 - val_seg_out_loss: 1.8034\nEpoch 142/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - cls_out_accuracy: 0.9986 - cls_out_loss: 0.0105 - loss: 1.7676 - seg_out_dice: 0.8384 - seg_out_loss: 1.7571\nEpoch 142: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 505ms/step - cls_out_accuracy: 0.9985 - cls_out_loss: 0.0106 - loss: 1.7676 - seg_out_dice: 0.8384 - seg_out_loss: 1.7570 - val_cls_out_accuracy: 0.6250 - val_cls_out_loss: 3.1656 - val_loss: 4.9758 - val_seg_out_dice: 0.6038 - val_seg_out_loss: 1.8102\nEpoch 143/200\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - cls_out_accuracy: 0.9972 - cls_out_loss: 0.0044 - loss: 1.7499 - seg_out_dice: 0.8389 - seg_out_loss: 1.7455\nEpoch 143: val_seg_out_dice did not improve from 0.65127\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 504ms/step - cls_out_accuracy: 0.9972 - cls_out_loss: 0.0044 - loss: 1.7500 - seg_out_dice: 0.8389 - seg_out_loss: 1.7456 - val_cls_out_accuracy: 0.7125 - val_cls_out_loss: 1.6031 - val_loss: 3.4099 - val_seg_out_dice: 0.6117 - val_seg_out_loss: 1.8068\nEpoch 144/200\n\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 487ms/step - cls_out_accuracy: 1.0000 - cls_out_loss: 8.9206e-04 - loss: 1.8021 - seg_out_dice: 0.7956 - seg_out_loss: 1.8012","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2154337150.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_aug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'seg_out'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cls_out'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf_labels_train_aug\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[1;32m    219\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":90},{"cell_type":"code","source":"model = load_model('/kaggle/working/best_model.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T17:05:18.833950Z","iopub.execute_input":"2025-07-29T17:05:18.834194Z","iopub.status.idle":"2025-07-29T17:05:21.113036Z","shell.execute_reply.started":"2025-07-29T17:05:18.834167Z","shell.execute_reply":"2025-07-29T17:05:21.112487Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"model=load_model('/kaggle/input/unet/keras/default/3/unet6582.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:39:19.280996Z","iopub.execute_input":"2025-07-30T04:39:19.281616Z","iopub.status.idle":"2025-07-30T04:39:20.477133Z","shell.execute_reply.started":"2025-07-30T04:39:19.281591Z","shell.execute_reply":"2025-07-30T04:39:20.476337Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def predict(model,X_test):\n    seg_preds, cls_preds = model.predict(X_test)\n    idx=0\n    for cls in cls_preds:\n        if(cls.argmax()==2):\n            seg_preds[idx][:]=0\n        idx=idx+1\n    return seg_preds, cls_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:37:13.714881Z","iopub.execute_input":"2025-07-30T04:37:13.715745Z","iopub.status.idle":"2025-07-30T04:37:13.720167Z","shell.execute_reply.started":"2025-07-30T04:37:13.715711Z","shell.execute_reply":"2025-07-30T04:37:13.719511Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"seg_preds, cls_preds = predict(model,X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:39:23.087433Z","iopub.execute_input":"2025-07-30T04:39:23.088148Z","iopub.status.idle":"2025-07-30T04:39:31.819361Z","shell.execute_reply.started":"2025-07-30T04:39:23.088121Z","shell.execute_reply":"2025-07-30T04:39:31.818805Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step  \n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"true_labels = df_labels_test.values.argmax(axis=1)\n\n# Predicted class indices\npredicted_labels = cls_preds.argmax(axis=1)\n\n# Accuracy\nacc = accuracy_score(true_labels, predicted_labels)\nprint(f\"\\n## Accuracy: {acc:.4f}\")\n\n# Classification report\nreport = classification_report(true_labels, predicted_labels, target_names=['benign', 'malignant', 'normal'])\nprint(\"\\n## Classification Report:\\n\", report)\n\n#segmentation\nprint(\"\\n## Dice Score:\\n\",dice(y_test,seg_preds).numpy())\nprint(\"\\n## IOU:\\n\",iou(y_test,seg_preds).numpy(),\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:39:33.120717Z","iopub.execute_input":"2025-07-30T04:39:33.121457Z","iopub.status.idle":"2025-07-30T04:39:33.193220Z","shell.execute_reply.started":"2025-07-30T04:39:33.121432Z","shell.execute_reply":"2025-07-30T04:39:33.192550Z"}},"outputs":[{"name":"stdout","text":"\n## Accuracy: 0.8125\n\n## Classification Report:\n               precision    recall  f1-score   support\n\n      benign       0.81      0.81      0.81        37\n   malignant       0.77      0.90      0.83        30\n      normal       1.00      0.62      0.76        13\n\n    accuracy                           0.81        80\n   macro avg       0.86      0.78      0.80        80\nweighted avg       0.83      0.81      0.81        80\n\n\n## Dice Score:\n 0.66862774\n\n## IOU:\n 0.5022095 \n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"def plot_prediction(image, predicted_mask, ground_truth_mask=None):\n    plt.figure(figsize=(12, 4))\n    predicted_mask =  (predicted_mask > 0.5).astype(np.float32)\n    # Fix image shape\n    image_2d = np.squeeze(image)\n    if image_2d.ndim == 3:  # if shape is (H, W, C)\n        image_2d = image_2d[:, :, 0]  # Take first channel\n\n    # Plot input image\n    plt.subplot(1, 3 if ground_truth_mask is not None else 2, 1)\n    plt.imshow(image_2d, cmap='gray')\n    plt.title(\"Ultrasound Image\")\n    plt.axis('off')\n\n    # Ground truth\n    if ground_truth_mask is not None:\n        gt_mask = np.squeeze(ground_truth_mask)\n        plt.subplot(1, 3, 2)\n        plt.imshow(gt_mask, cmap='gray')\n        plt.title(\"Ground Truth Mask\")\n        plt.axis('off')\n\n    # Predicted mask\n    pred_mask = np.squeeze(predicted_mask)\n    plt.subplot(1, 3 if ground_truth_mask is not None else 2, 3 if ground_truth_mask is not None else 2)\n    plt.imshow(pred_mask, cmap='gray')\n    plt.title(\"Predicted Mask\")\n    plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:39:36.878861Z","iopub.execute_input":"2025-07-30T04:39:36.879532Z","iopub.status.idle":"2025-07-30T04:39:36.885505Z","shell.execute_reply.started":"2025-07-30T04:39:36.879506Z","shell.execute_reply":"2025-07-30T04:39:36.884850Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"n=78\nplot_prediction(X_test[n],seg_preds[n],y_test[n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(15,25):\n    plot_prediction(X_test[i],seg_preds[i],y_test[i])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" model.summary()\n# print(\"\\n\\n## Model Plot\")\n# plot_model(model, show_shapes=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:10:15.867887Z","iopub.execute_input":"2025-07-29T15:10:15.868600Z","iopub.status.idle":"2025-07-29T15:10:15.988186Z","shell.execute_reply.started":"2025-07-29T15:10:15.868575Z","shell.execute_reply":"2025-07-29T15:10:15.987300Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_138 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m320\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_85    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m128\u001b[0m │ conv2d_138[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_129            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_129[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_139 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_86    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_139[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_130            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_140 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ activation_130[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_87    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_140[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_131            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ activation_131[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_141 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_88    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_141[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_132            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_142 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,584\u001b[0m │ activation_132[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_89    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_142[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_133            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_143 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,584\u001b[0m │ activation_133[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_90    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_143[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_134            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_134[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_144 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_91    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_144[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_135            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_145 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ activation_135[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_92    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_145[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_136            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_146 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ activation_136[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_93    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_146[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_137            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_147 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ activation_137[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_94    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_147[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_138            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_138[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_151 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ activation_138[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_152 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ activation_138[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_148 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_98    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_151[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_99    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_152[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_95    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_148[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_142            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_143            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_139            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ activation_142[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling2d      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ activation_143[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_149 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ activation_139[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ global_max_pooling2d[\u001b[38;5;34m…\u001b[0m │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_96    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_149[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply (\u001b[38;5;33mMultiply\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n│                           │                        │                │ activation_138[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_1 (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ activation_138[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_140            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│                           │                        │                │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_150 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ activation_140[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_153 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_97    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_150[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_156 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,584\u001b[0m │ activation_134[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_157 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,584\u001b[0m │ activation_134[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_100   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_153[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_141            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_103   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_156[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_104   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_157[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_144            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ up_sampling2d_30          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_141[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mUpSampling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_147            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_148            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_33            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m768\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_144[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ up_sampling2d_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ activation_147[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling2d_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ activation_148[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_154 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m1,769,728\u001b[0m │ concatenate_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ global_max_pooling2d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_101   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_154[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_2 (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ activation_134[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_3 (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ activation_134[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_145            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n│                           │                        │                │ multiply_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_155 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ activation_145[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_158 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,584\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_102   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_155[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_161 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ activation_131[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_162 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ activation_131[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_105   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_158[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_146            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_108   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_161[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_109   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_162[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_149            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ up_sampling2d_31          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_146[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mUpSampling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_152            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_153            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_34            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_149[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ up_sampling2d_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ activation_152[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling2d_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ activation_153[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_159 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m442,496\u001b[0m │ concatenate_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_4 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_5 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ global_max_pooling2d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_106   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_159[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_4 (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ reshape_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ activation_131[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_5 (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ reshape_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ activation_131[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_150            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ multiply_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n│                           │                        │                │ multiply_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_160 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,584\u001b[0m │ activation_150[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_163 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_107   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_160[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_166 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m9,248\u001b[0m │ activation_129[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_167 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m9,248\u001b[0m │ activation_129[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_110   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_163[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_151            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_113   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m128\u001b[0m │ conv2d_166[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_114   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m128\u001b[0m │ conv2d_167[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_154            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ up_sampling2d_32          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_151[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mUpSampling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_157            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_158            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_35            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m192\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_154[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ up_sampling2d_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ activation_157[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling2d_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ activation_158[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_164 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m110,656\u001b[0m │ concatenate_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_7 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ global_max_pooling2d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_111   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_164[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_6 (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ reshape_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ activation_129[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_7 (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ activation_129[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_155            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_3 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ multiply_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n│                           │                        │                │ multiply_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_165 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ activation_155[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_168 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m9,248\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_112   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_165[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_115   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m128\u001b[0m │ conv2d_168[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_156            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_159            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ up_sampling2d_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_156[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mUpSampling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_36            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_159[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ up_sampling2d_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_169 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m27,680\u001b[0m │ concatenate_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_116   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m128\u001b[0m │ conv2d_169[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_160            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_171 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m2,305\u001b[0m │ activation_138[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_172 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m4,609\u001b[0m │ activation_141[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_173 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m2,305\u001b[0m │ activation_146[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_170 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │            \u001b[38;5;34m289\u001b[0m │ activation_160[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ conv2d_171[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ conv2d_172[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ conv2d_173[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_117   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m4\u001b[0m │ conv2d_170[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_37            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ global_average_poolin… │\n│                           │                        │                │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_161            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m128\u001b[0m │ concatenate_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ seg_out (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_161[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ cls_out (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m99\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_138 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_85    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_138[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_129            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_129[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_139 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_86    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_139[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_130            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_140 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_130[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_87    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_140[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_131            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_131[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_141 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_88    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_141[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_132            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_142 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_132[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_89    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_142[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_133            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_143 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_133[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_90    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_143[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_134            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_134[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_144 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_91    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_144[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_135            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_145 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ activation_135[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_92    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_145[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_136            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_146 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ activation_136[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_93    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_146[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_137            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_147 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ activation_137[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_94    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_147[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_138            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_138[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_151 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ activation_138[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_152 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ activation_138[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_148 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_98    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_151[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_99    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_152[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_95    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_148[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_142            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_143            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_139            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_142[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling2d      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_143[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_149 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ activation_139[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_96    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_149[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n│                           │                        │                │ activation_138[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ activation_138[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_140            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│                           │                        │                │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_150 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ activation_140[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_153 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_97    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_150[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_134[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_157 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_134[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_100   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_153[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_141            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_103   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_156[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_104   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_157[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_144            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ up_sampling2d_30          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_141[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_147            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_148            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_33            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_144[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ up_sampling2d_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_147[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling2d_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_148[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_154 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,769,728</span> │ concatenate_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling2d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_101   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_154[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ activation_134[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ activation_134[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_145            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n│                           │                        │                │ multiply_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ activation_145[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_158 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_102   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_155[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_161 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_131[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_162 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_131[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_105   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_158[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_146            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_108   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_161[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_109   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_162[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_149            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ up_sampling2d_31          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_146[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_152            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_153            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_34            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_149[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ up_sampling2d_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_152[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling2d_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_153[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_159 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">442,496</span> │ concatenate_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling2d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_106   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_159[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ activation_131[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ activation_131[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_150            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n│                           │                        │                │ multiply_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_160 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_150[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_163 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_107   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_160[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_166 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_129[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_167 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_129[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_110   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_163[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_151            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_113   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_166[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_114   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_167[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_154            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ up_sampling2d_32          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_151[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_157            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_158            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_35            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_154[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ up_sampling2d_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_157[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling2d_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_158[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_164 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">110,656</span> │ concatenate_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling2d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_111   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_164[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ activation_129[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ activation_129[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_155            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n│                           │                        │                │ multiply_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_165 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_155[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_168 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_112   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_165[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_115   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_168[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_156            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_159            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ up_sampling2d_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_156[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_36            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_159[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ up_sampling2d_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_169 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span> │ concatenate_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_116   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_169[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_160            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_171 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,305</span> │ activation_138[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_172 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,609</span> │ activation_141[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_173 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,305</span> │ activation_146[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_170 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │ activation_160[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_171[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_172[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_173[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_117   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │ conv2d_170[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_37            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ global_average_poolin… │\n│                           │                        │                │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_161            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ concatenate_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ seg_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_161[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ cls_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,898,251\u001b[0m (53.02 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,898,251</span> (53.02 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,887,305\u001b[0m (52.98 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,887,305</span> (52.98 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m10,946\u001b[0m (42.76 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,946</span> (42.76 KB)\n</pre>\n"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}